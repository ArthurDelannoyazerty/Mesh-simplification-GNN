{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Transformation import Transformation\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import networkx as nx\n",
    "import torch\n",
    "from numpy import mean\n",
    "from igraph import Graph as igraphGraph\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import scipy.spatial.distance\n",
    "from scipy.spatial.distance import cdist\n",
    "from shapely.geometry import LineString, MultiLineString, Polygon, MultiPolygon, LinearRing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 5999\n",
      "Number of edges: 17991\n"
     ]
    }
   ],
   "source": [
    "transformation = Transformation()\n",
    "\n",
    "user_number_triangles = 500   #Ã  diminuer si le process est trop long\n",
    "number_neigh_tri = 20\n",
    "\n",
    "# Create objects\n",
    "stl_file_path = \"3d_models/stl/Handle.stl\"\n",
    "mesh_data = transformation.stl_to_mesh(stl_file_path)\n",
    "graph = transformation.mesh_to_graph(mesh_data)\n",
    "\n",
    "transformation.print_graph_properties(graph, display_graph=False, display_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(graph._node)<20:\n",
    "    raise Exception(\"Input mesh does not have enough vertices. (More than 20 is needed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DevConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(array):\n",
    "    return np.maximum(array, 0)\n",
    "\n",
    "def sigmoid(array):\n",
    "    return 1 / (1 + np.exp(-array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DevConv():\n",
    "    def __init__(self, graph, output_dimension):\n",
    "        self.graph = graph\n",
    "        self.list_node = list(graph._node)\n",
    "\n",
    "        self.W_phi = np.random.random((output_dimension))      #change\n",
    "        self.W_theta = np.array([0.1, 0.1, 0.1]).reshape(1, -1)  # change\n",
    "    \n",
    "    def forward(self, previous_inclusion_score, return_flatten=True):\n",
    "        list_inc_score = np.zeros((len(self.list_node), len(self.W_phi)))                               #list of \"output_dimension\" for each \"list_node\" element\n",
    "        for index_current_node, (current_node, dict_neigh) in enumerate(self.graph._adj.items()):       # for each node and its adjacency nodes\n",
    "            neigh_nodes = np.array(list(dict_neigh.keys()))                                             # array of adjacency nodes\n",
    "            diff = current_node - neigh_nodes                                                           # Compute the differences between current_node and all neighbor nodes   (x_i - x_j)\n",
    "            neigh_distances = np.linalg.norm(self.W_theta * diff, axis=1)                               # Compute the norm for each vector difference  ||W_theta * (x_i - x_j)||\n",
    "            list_inc_score[index_current_node] = self.W_phi * np.max(neigh_distances)                   # Add (W_phi * ||W_theta * (x_i - x_j)||) to the inclusion score list\n",
    "\n",
    "        if len(previous_inclusion_score)==0:                            # return if no previous inclusion score\n",
    "            if return_flatten:\n",
    "                list_inc_score = list_inc_score.flatten()\n",
    "            return list_inc_score\n",
    "        \n",
    "        if list_inc_score.shape[1]!=1:                                  # If inclusion score is not vector\n",
    "            list_inc_score = np.mean(list_inc_score, axis=1)            # Mean the matrix for each node\n",
    "\n",
    "        # array of array to array\n",
    "        if len(list_inc_score.shape)==2:                 \n",
    "            if list_inc_score.shape[1]==1:\n",
    "                list_inc_score = list_inc_score.flatten()\n",
    "\n",
    "        # Return the mean of previous and current inclusion score\n",
    "        return np.mean(np.array([previous_inclusion_score, list_inc_score], dtype=np.float64), axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.22157599 1.22228672 1.22157599 ... 1.13724611 1.6508054  1.13724611]\n",
      "[0.94448555 0.94503506 0.94448555 ... 0.87928424 1.27635273 0.87928424]\n",
      "[0.74821541 0.74833477 0.74821541 ... 0.7337888  0.81333141 0.7337888 ]\n",
      "(5999,)\n"
     ]
    }
   ],
   "source": [
    "devconv = DevConv(graph, 1)\n",
    "inclusion_score = devconv.forward(previous_inclusion_score=np.array([]))\n",
    "inclusion_score = relu(inclusion_score)\n",
    "print(inclusion_score)\n",
    "\n",
    "devconv = DevConv(graph, 64)\n",
    "inclusion_score = devconv.forward(previous_inclusion_score=inclusion_score)\n",
    "inclusion_score = relu(inclusion_score)\n",
    "print(inclusion_score)\n",
    "\n",
    "devconv = DevConv(graph, 1)\n",
    "inclusion_score = devconv.forward(previous_inclusion_score=inclusion_score)\n",
    "inclusion_score = sigmoid(inclusion_score)\n",
    "print(inclusion_score)\n",
    "print(inclusion_score.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "normalized_inclusion_score = inclusion_score / np.sum(inclusion_score)  # normalize for multinomial sampling\n",
    "normalized_inclusion_score = np.round(normalized_inclusion_score, 8)    # round to remove float imprecision\n",
    "\n",
    "number_throws = 500     # small:more randomness    |   big:less randomness\n",
    "mult_sampling = np.random.multinomial(number_throws, normalized_inclusion_score)\n",
    "print(mult_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[88.630486 ,  3.5589852, 91.10313  ],\n",
       "       [90.12466  ,  4.1574683, 87.93393  ],\n",
       "       [75.70441  ,  6.9390492, 84.51398  ],\n",
       "       [90.45635  ,  4.1574683, 87.13314  ],\n",
       "       [86.91348  ,  3.5589852, 93.11348  ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_number_point = min(len(graph._node), user_number_triangles*3)   # number of points for the simplification\n",
    "\n",
    "index_k_nodes = np.argpartition(mult_sampling, -target_number_point)[-target_number_point:]     # Take the k (\"target_number_points\") largest values given by the multinomial sampling \n",
    "list_k_nodes = np.array(graph)[index_k_nodes]                                # Take the selected nodes (list of list of 3)\n",
    "list_k_nodes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN extended graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n_, indices = NearestNeighbors(n_neighbors=15).fit(list_k_nodes).kneighbors(list_k_nodes)        # KNN of the selected points\\n\\nextended_graph = nx.Graph()\\nfor index_poly, poly in enumerate(indices):                                 # For the neighbors of the 'index_poly' node\\n    current_node = tuple(list_k_nodes[poly[0]])                             # Tuple of the main node coordinates\\n    for index_other_node in poly[1:]:                                       # For every neighbors of the main node (main node is the first index)\\n        edge = current_node, tuple(list_k_nodes[index_other_node])          # Create an edge of two tuples\\n        extended_graph.add_edge(*edge)                                      # Add the edge to the graph\\n\\ntransformation.print_graph_properties(graph=extended_graph, display_graph=False, display_labels=False)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "_, indices = NearestNeighbors(n_neighbors=15).fit(list_k_nodes).kneighbors(list_k_nodes)        # KNN of the selected points\n",
    "\n",
    "extended_graph = nx.Graph()\n",
    "for index_poly, poly in enumerate(indices):                                 # For the neighbors of the 'index_poly' node\n",
    "    current_node = tuple(list_k_nodes[poly[0]])                             # Tuple of the main node coordinates\n",
    "    for index_other_node in poly[1:]:                                       # For every neighbors of the main node (main node is the first index)\n",
    "        edge = current_node, tuple(list_k_nodes[index_other_node])          # Create an edge of two tuples\n",
    "        extended_graph.add_edge(*edge)                                      # Add the edge to the graph\n",
    "\n",
    "transformation.print_graph_properties(graph=extended_graph, display_graph=False, display_labels=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 1500\n",
      "Number of edges: 11764\n"
     ]
    }
   ],
   "source": [
    "def knn_and_extended_graph(list_k_nodes_i, k_neighbors=15):\n",
    "    \"\"\"\n",
    "    Perform k-NN on the given points and construct an extended graph.\n",
    "\n",
    "    Parameters:\n",
    "    - list_k_nodes_i: array-like\n",
    "        List of coordinates of the selected points.\n",
    "    - k_neighbors: int, optional (default=15)\n",
    "        Number of neighbors for k-NN.\n",
    "\n",
    "    Returns:\n",
    "    - extended_graph_i: networkx.Graph\n",
    "        Extended graph.\n",
    "    \"\"\"\n",
    "\n",
    "    # Perform k-NN on the selected points\n",
    "    _, indices = NearestNeighbors(n_neighbors=k_neighbors).fit(list_k_nodes_i).kneighbors(list_k_nodes_i)\n",
    "\n",
    "    # Construct the extended graph\n",
    "    extended_graph_i = nx.Graph()\n",
    "    for poly in indices:\n",
    "        current_node = tuple(list_k_nodes_i[poly[0]])\n",
    "        for index_other_node in poly[1:]:\n",
    "            edge = current_node, tuple(list_k_nodes_i[index_other_node])\n",
    "            extended_graph_i.add_edge(*edge)\n",
    "\n",
    "    return extended_graph_i\n",
    "\n",
    "extended_graph = knn_and_extended_graph(list_k_nodes)\n",
    "transformation.print_graph_properties(graph=extended_graph, display_graph=False, display_labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devconv = DevConv(extended_graph, 64)\n",
    "inclusion_score = devconv.forward(previous_inclusion_score=np.array([]), return_flatten=False)\n",
    "inclusion_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "inclusion_score = [[f_1_1  , f_1_2  , ..., f_63_1  ],\n",
    "                    ...,\n",
    "                   [f_1_M-1, f_1_M-1, ..., f_63_M-1]]\n",
    "M = number of points\n",
    "64 = hidden dimensions\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "f = np.mean(inclusion_score, axis=1)                            # Flatten the matrix of inclusion score \n",
    "wq = np.random.rand(64)\n",
    "wk = np.random.rand(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wq_f = wq.reshape(-1, 1) * f            # Wq*f\n",
    "wk_f = wk.reshape(-1, 1) * f            # Wq*f\n",
    "S = np.exp(np.dot(wq_f.T, wk_f))        # e^((wq_f.T)*(wk_f))\n",
    "\n",
    "nodes = list(extended_graph.nodes())                                                                                # list of nodes\n",
    "node_indices = {node: index for index, node in enumerate(nodes)}                                                    # dict{node: index}\n",
    "neighbors_indices = [[node_indices[neighbor] for neighbor in extended_graph.neighbors(node)] for node in nodes]     # List of list : [[neigh1 of node1, neigh2 of node1...], [neigh1 of node2, neigh2 of node2...]...]\n",
    "\n",
    "\n",
    "for index_current_node, neighbors_index in enumerate(neighbors_indices):        # For each neighbors of the 'index_current_node' node\n",
    "    sum_columns = np.sum(S[:, neighbors_index], axis=1)                         # Sum along the rows the values of the neighbors\n",
    "    S[index_current_node] = S[index_current_node] / sum_columns                 # And divide the current node columns by the sume of the neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S = S*np.random.choice([0, 1], size=S.shape)      # Add a random mask to emulate the 'sparse'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 249)\t1\n",
      "  (0, 250)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 9)\t1\n",
      "  :\t:\n",
      "  (1498, 1446)\t1\n",
      "  (1498, 1447)\t1\n",
      "  (1498, 1450)\t1\n",
      "  (1498, 1451)\t1\n",
      "  (1498, 1453)\t1\n",
      "  (1498, 1490)\t1\n",
      "  (1498, 1492)\t1\n",
      "  (1498, 1494)\t1\n",
      "  (1498, 1495)\t1\n",
      "  (1498, 1496)\t1\n",
      "  (1498, 1497)\t1\n",
      "  (1499, 1201)\t1\n",
      "  (1499, 1202)\t1\n",
      "  (1499, 1205)\t1\n",
      "  (1499, 1206)\t1\n",
      "  (1499, 1207)\t1\n",
      "  (1499, 1208)\t1\n",
      "  (1499, 1257)\t1\n",
      "  (1499, 1258)\t1\n",
      "  (1499, 1265)\t1\n",
      "  (1499, 1489)\t1\n",
      "  (1499, 1490)\t1\n",
      "  (1499, 1491)\t1\n",
      "  (1499, 1493)\t1\n",
      "  (1499, 1497)\t1\n",
      "[[0.06218101 0.06217998 0.06217998 ... 0.06163289 0.06159952 0.06173376]\n",
      " [1.18470407 0.05970745 0.05970745 ... 0.06096624 0.06103535 0.06075266]\n",
      " [1.18477581 0.58602112 0.0595572  ... 0.06058806 0.06064415 0.06041435]\n",
      " ...\n",
      " [1.88740486 1.90758249 1.91994679 ... 0.06255528 0.06239804 0.0630314 ]\n",
      " [1.60830072 1.60828805 1.62086095 ... 0.02976713 0.03348301 0.03696118]\n",
      " [1.91244329 1.92558062 1.93892943 ... 0.01870478 1.40130615 0.05424958]]\n"
     ]
    }
   ],
   "source": [
    "adjacency = nx.adjacency_matrix(extended_graph)\n",
    "# S = np.random.rand(target_number_point, target_number_point)\n",
    "print(adjacency)\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_s = np.zeros((target_number_point,target_number_point))   # Init A_s to 0\n",
    "A_s = np.matmul(np.matmul(S, adjacency.toarray()), S.T)     # A_s = S * A * S.T\n",
    "A_s = A_s/A_s.max()                                         # Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.35579065e-23 4.33157335e-23 4.33581497e-23 ... 9.79439598e-21\n",
      "  5.99966509e-21 7.17399893e-21]\n",
      " [4.33157335e-23 4.31251248e-23 4.34371052e-23 ... 1.04303516e-20\n",
      "  6.34431728e-21 7.53983526e-21]\n",
      " [4.33581497e-23 4.34371052e-23 4.37505446e-23 ... 1.02820187e-20\n",
      "  6.26151216e-21 7.44690542e-21]\n",
      " ...\n",
      " [9.79439598e-21 1.04303516e-20 1.02820187e-20 ... 1.21731570e-17\n",
      "  6.91291112e-18 7.47841147e-18]\n",
      " [5.99966509e-21 6.34431728e-21 6.26151216e-21 ... 6.91291112e-18\n",
      "  6.07665355e-18 4.49333851e-18]\n",
      " [7.17399893e-21 7.53983526e-21 7.44690542e-21 ... 7.47841147e-18\n",
      "  4.49333851e-18 4.89021958e-18]]\n",
      "(1500, 1500)\n"
     ]
    }
   ],
   "source": [
    "print(A_s)  # symmÃ©trique\n",
    "print(A_s.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TriConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH U--- 1500 11764 -- \n",
      "+ attr: _nx_name (v)\n"
     ]
    }
   ],
   "source": [
    "igraph_g = igraphGraph(directed=extended_graph.is_directed()).from_networkx(extended_graph)\n",
    "print(igraph_g.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 863  864 1294]\n",
      " [1466 1467 1468]\n",
      " [ 661  662  664]]\n",
      "32574\n"
     ]
    }
   ],
   "source": [
    "triangles_ids_igraph = np.array(igraph_g.cliques(min=3, max=3))\n",
    "print(triangles_ids_igraph[:3])\n",
    "print(len(triangles_ids_igraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 75.93793     4.4479885  81.95952  ]\n",
      "  [ 75.85339     4.4479885  82.0534   ]\n",
      "  [ 75.85237     5.0095077  82.51254  ]]\n",
      "\n",
      " [[ 76.07001    -5.5423326  82.847664 ]\n",
      "  [ 76.15477    -5.5423326  82.789406 ]\n",
      "  [ 76.23637    -5.5423326  82.72679  ]]\n",
      "\n",
      " [[ 51.         -7.234973  -10.009508 ]\n",
      "  [ 51.         -5.4119864 -11.939049 ]\n",
      "  [ 51.         -4.303499  -12.67593  ]]]\n",
      "32574\n"
     ]
    }
   ],
   "source": [
    "triangles = np.array(igraph_g.vs['_nx_name'])[triangles_ids_igraph]   #les triangles\n",
    "# triangles = [list(map(tuple, row)) for row in triangles.tolist()]\n",
    "print(triangles[:3])\n",
    "print(len(triangles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32574,)\n",
      "[9.37965871e-21 1.25460741e-19 5.01768731e-07 ... 3.86950923e-12\n",
      " 5.02163751e-12 4.54471065e-12]\n"
     ]
    }
   ],
   "source": [
    "# Extract indices for each triangle\n",
    "i, j, k = triangles_ids_igraph.T\n",
    "\n",
    "# Extract probabilities using advanced indexing\n",
    "A_s_ij = A_s[i, j]\n",
    "A_s_ik = A_s[i, k]\n",
    "A_s_jk = A_s[j, k]\n",
    "\n",
    "# Calculate the barycenter probabilities\n",
    "p_init = np.zeros(len(triangles))\n",
    "p_init = (A_s_ij + A_s_ik + A_s_jk) / 3\n",
    "\n",
    "print(p_init.shape)\n",
    "print(p_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate barycenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32574, 3)\n",
      "[[ 75.88123     4.635162   82.17515  ]\n",
      " [ 76.15372    -5.542333   82.78796  ]\n",
      " [ 51.         -5.6501527 -11.541496 ]]\n"
     ]
    }
   ],
   "source": [
    "barycenters = np.mean(triangles, axis=1)\n",
    "print(barycenters.shape)\n",
    "print(barycenters[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Tri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, indices_neigh_tri = NearestNeighbors(n_neighbors=number_neigh_tri).fit(barycenters).kneighbors(barycenters)          # Find k='number_neigh_tri' neighbors of each triangles based on theirs barycenters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diff Barycenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32574, 19, 3)\n"
     ]
    }
   ],
   "source": [
    "# Calculates the difference between each barycenters and their n='number_neigh_tri'-1 neighbors\n",
    "barycenters_diff = np.subtract(barycenters[indices_neigh_tri[:, 0]][:, np.newaxis], barycenters[indices_neigh_tri[:, 1:]])   #Inverser la diffÃ©rence des barycentres si nÃ©cÃ©ssaire\n",
    "\n",
    "print(barycenters_diff.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate e norm matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32574, 3)\n",
      "[[0.12633029 0.79275435 0.72534025]\n",
      " [0.10285278 0.2056343  0.10285201]]\n"
     ]
    }
   ],
   "source": [
    "diff_vectors = list()\n",
    "\n",
    "for triangle in triangles:\n",
    "    e_ij = np.linalg.norm(np.array(triangle[0]) - np.array(triangle[1]))    #Calculate the vectors for each edge of each triangles\n",
    "    e_ik = np.linalg.norm(np.array(triangle[0]) - np.array(triangle[2]))\n",
    "    e_jk = np.linalg.norm(np.array(triangle[1]) - np.array(triangle[2]))\n",
    "    diff_vectors.append([e_ij, e_ik, e_jk])\n",
    "\n",
    "diff_vectors = np.array(diff_vectors)\n",
    "print(diff_vectors.shape)\n",
    "print(diff_vectors[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32574,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_diff_vectors = diff_vectors.max(axis=1)       # calculate t_n_max\n",
    "min_diff_vectors = diff_vectors.min(axis=1)       # calculate t_n_min\n",
    "max_diff_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32574, 19)\n",
      "(32574, 19)\n"
     ]
    }
   ],
   "source": [
    "max_diff_vectors_diff = np.subtract(max_diff_vectors[indices_neigh_tri[:, 0]][:, np.newaxis], max_diff_vectors[indices_neigh_tri[:, 1:]])   #Inverser la diffÃ©rence des barycentres si nÃ©cÃ©ssaire   # calculate t_n_max - t_m_max\n",
    "print(max_diff_vectors_diff.shape)\n",
    "min_diff_vectors_diff = np.subtract(min_diff_vectors[indices_neigh_tri[:, 0]][:, np.newaxis], min_diff_vectors[indices_neigh_tri[:, 1:]])   #Inverser la diffÃ©rence des barycentres si nÃ©cÃ©ssaire   # calculate t_n_min - t_m_min\n",
    "print(min_diff_vectors_diff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32574, 19, 5)\n"
     ]
    }
   ],
   "source": [
    "r_matrix = np.zeros((len(triangles), number_neigh_tri-1, 5))\n",
    "\n",
    "r_matrix[:, :, 0]   = min_diff_vectors_diff\n",
    "r_matrix[:, :, 1]   = max_diff_vectors_diff\n",
    "r_matrix[:, :, 2:5] = barycenters_diff\n",
    "\n",
    "print(r_matrix.shape)  # nb_triangles, len(indices_neigh_tri), 5dim/triangles\n",
    "\n",
    "# Here r_matrix[i,j] represent the relation between the triangles (n = i) and (m = indices_neigh_tri_array[i,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000000000000003\n",
      "(32574,)\n",
      "[3.06937787e-05 3.06937787e-05 3.06937941e-05 ... 3.06937787e-05\n",
      " 3.06937787e-05 3.06937787e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arthur\\AppData\\Local\\Temp\\ipykernel_1440\\474768578.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  final_scores = torch.nn.functional.softmax(torch.tensor(f_final))    #proba des triangles\n"
     ]
    }
   ],
   "source": [
    "# Multi Layer Perceptron (MLP) * 3 \n",
    "f_final = p_init    # TODO\n",
    "\n",
    "\n",
    "final_scores = torch.nn.functional.softmax(torch.tensor(f_final))    #proba des triangles\n",
    "final_scores = final_scores.numpy()\n",
    "print(final_scores.sum())\n",
    "print(final_scores.shape)\n",
    "print(final_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 3, 3)\n",
      "[[51.         8.492921  87.695595 ]\n",
      " [51.        -1.8187612 81.39     ]\n",
      " [39.         7.4193583 85.26786  ]]\n"
     ]
    }
   ],
   "source": [
    "selected_triangles_indexes = np.argpartition(final_scores, -int(target_number_point/3))[-int(target_number_point/3):] \n",
    "selected_triangles = np.array(triangles)[selected_triangles_indexes]\n",
    "print(selected_triangles.shape) # number triangles, number points, number dimensions(x,y,z)\n",
    "print(selected_triangles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 50\n",
      "Number of edges: 234\n"
     ]
    }
   ],
   "source": [
    "simplified_final_graph = nx.Graph()\n",
    "for index_poly, poly in enumerate(selected_triangles):\n",
    "    for index_current_node in range(len(poly)):\n",
    "        current_node = tuple(poly[index_current_node])\n",
    "        for index_other_node in range(index_current_node+1, len(poly)):\n",
    "            edge = current_node, tuple(poly[index_other_node])\n",
    "            simplified_final_graph.add_edge(*edge)\n",
    "            # if attribute do not exists\n",
    "            if len(simplified_final_graph.nodes[current_node])==0:\n",
    "                simplified_final_graph.nodes[current_node]['index_triangle'] = set()\n",
    "            simplified_final_graph.nodes[current_node]['index_triangle'].add(index_poly)\n",
    "            if len(simplified_final_graph.nodes[tuple(poly[index_other_node])])==0:\n",
    "                simplified_final_graph.nodes[tuple(poly[index_other_node])]['index_triangle'] = set()\n",
    "            simplified_final_graph.nodes[tuple(poly[index_other_node])]['index_triangle'].add(index_poly)\n",
    "            \n",
    "transformation.print_graph_properties(graph=simplified_final_graph, display_graph=False, display_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_final_mesh = transformation.graph_to_mesh(simplified_final_graph)\n",
    "\n",
    "#Affichage\n",
    "transformation.mesh_to_display_vtk(mesh_data)\n",
    "transformation.mesh_to_display_vtk(simplified_final_mesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Chamfer distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RÃ©cupÃ©ration des points de l'espace de dÃ©part P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les points avant K-NN :  [[75.0252     -0.66553295  3.8       ]\n",
      " [75.01418    -0.49935842 16.7       ]\n",
      " [75.          0.          3.8       ]\n",
      " ...\n",
      " [51.         -8.57404    -6.9813724 ]\n",
      " [39.         -8.699333   -6.327254  ]\n",
      " [51.         -8.699333   -6.327254  ]]\n",
      "dim points avant K-NN :  5999\n"
     ]
    }
   ],
   "source": [
    "keys_input = np.array(graph)\n",
    "print(\"Les points avant K-NN : \", keys_input)\n",
    "print(\"dim points avant K-NN : \", len(keys_input))  #return 5999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RÃ©cupÃ©ration des points de l'espace de dÃ©part Ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled points :  [[88.630486   3.5589852 91.10313  ]\n",
      " [88.8296     2.9401166 91.24779  ]\n",
      " [88.28478    2.9401166 91.9578   ]\n",
      " ...\n",
      " [83.630974   8.114116  -4.8309755]\n",
      " [81.69544    7.5075808 -7.796847 ]\n",
      " [86.931366   7.5075808 -2.2793348]]\n",
      "dim sample points :  1500\n"
     ]
    }
   ],
   "source": [
    "keys_output = np.array(extended_graph)\n",
    "print(\"sampled points : \", keys_output)\n",
    "print(\"dim sample points : \", len(keys_output))  #return: 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squared Euclidean Distances Matrix Shape: (1500, 5999)\n",
      "Distances Matrix:\n",
      " [[ 7824.78626084  5737.69896997  7820.29242132 ... 11183.8326739\n",
      "  12106.13047905 11058.99882622]\n",
      " [ 7850.67764431  5760.06816828  7847.01759486 ... 11212.62209901\n",
      "  12139.35426034 11087.44392098]\n",
      " [ 7960.6152675   5851.67541597  7956.92775949 ... 11311.69099855\n",
      "  12224.41873126 11185.58395343]\n",
      " ...\n",
      " [  225.6353133    612.02396003   214.82632067 ...  1347.89921363\n",
      "   2276.85473658  1349.711365  ]\n",
      " [  245.77877622   708.8458426    235.67957122 ...  1201.49370997\n",
      "   2087.72454808  1207.03393528]\n",
      " [  245.51488909   566.34550151   235.67957349 ...  1571.79075703\n",
      "   2576.46555168  1570.11276847]]\n"
     ]
    }
   ],
   "source": [
    "def matrix_distance_euclidienne_barycentres(barycentre_b, barycentre_b_hat):\n",
    "    \"\"\"\n",
    "    Calculate distances between barycenters b et b_hat after the k-NN process.\n",
    "\n",
    "    Parameters:\n",
    "    - b_hat: array-like, shape (M, 3)\n",
    "        Barycenters after k-NN.\n",
    "    - number_neigh: int, optional (default=3)\n",
    "        Number of neighbors for k-NN.\n",
    "\n",
    "    Returns:\n",
    "    - distances_after: array-like, shape (M, M)\n",
    "        Matrix of distances between barycenters after the k-NN process.\n",
    "    \"\"\"\n",
    "    return cdist(barycentre_b, barycentre_b_hat, metric='sqeuclidean').T\n",
    "\n",
    "distances_matrix = matrix_distance_euclidienne_barycentres(keys_input, keys_output)\n",
    "print(\"Squared Euclidean Distances Matrix Shape:\", distances_matrix.shape)\n",
    "print(\"Distances Matrix:\\n\", distances_matrix)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le min des x de distances_matrix\n",
    "def min_pour_x_list(distances_matrix, x_in):\n",
    "    return np.min(distances_matrix[:, x_in])\n",
    "\n",
    "# Calculer le min des y de distances_matrix\n",
    "def min_pour_y_list(distances_matrix, y_out):\n",
    "    return np.min(distances_matrix[y_out, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_P_Ps(keys_x, keys_y, p_y):\n",
    "    \"\"\"\n",
    "    Calculate the Probabilistic Chamfer distance between two sets of points.\n",
    "\n",
    "    Parameters:\n",
    "    - keys_x (list): The input vertex set, a list of tuples.\n",
    "    - keys_y (list): The sampled points, a list of tuples.\n",
    "    - p_y (list): Their respective probabilities, a weight associated with each point in keys_y.\n",
    "\n",
    "    Returns:\n",
    "        chamfer_distance (float): The Probabilistic Chamfer distance between the two sets of points.\n",
    "    \"\"\"\n",
    "    min_for_x = [p_y[i] * min_pour_x_list(distances_matrix, i) for i in range(len(keys_x))]\n",
    "    min_for_y = [p_y[j] * min_pour_y_list(distances_matrix, j) for j in range(len(keys_y))]\n",
    "    \n",
    "    sum_for_y = np.sum(min_for_y)\n",
    "    sum_for_x = np.sum(min_for_x)\n",
    "\n",
    "    chamfer_distance = sum_for_y + sum_for_x\n",
    "    \n",
    "    return chamfer_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBA :  [0.00022071 0.00022075 0.00022071 ... 0.00021646 0.00023992 0.00021646]\n"
     ]
    }
   ],
   "source": [
    "print(\"PROBA : \", normalized_inclusion_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chamfer Distance: 4.538946063021137\n"
     ]
    }
   ],
   "source": [
    "prob_chamfer_dist = d_P_Ps(keys_input, keys_output, normalized_inclusion_score)\n",
    "print(\"Chamfer Distance:\", prob_chamfer_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Surfaces Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "barycentres b et b_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH U--- 5999 17991 -- \n",
      "+ attr: _nx_name (v), index_triangle (v)\n",
      "triangles shape :  (11994, 3, 3)\n",
      "[[39.        8.793697 -4.666995]\n",
      " [51.        8.793697 -4.666995]\n",
      " [39.        8.793697 -5.333005]]\n",
      "shape b :  (11994, 3)\n",
      "Barycentre b:  [[43.          8.793697   -4.8889985 ]\n",
      " [55.          1.0515273   3.7313068 ]\n",
      " [55.         -8.515905   -2.804371  ]\n",
      " ...\n",
      " [75.05613    -0.94137865 21.        ]\n",
      " [75.01313    -0.3882971   8.099999  ]\n",
      " [75.03516    -0.72036856 25.300001  ]]\n"
     ]
    }
   ],
   "source": [
    "# Creation igraph\n",
    "igraph_g_original = igraphGraph(directed=extended_graph.is_directed()).from_networkx(graph)\n",
    "print(igraph_g_original.summary())\n",
    "\n",
    "#Find triangles\n",
    "triangles_ids_igraph_original = np.array(igraph_g_original.cliques(min=3, max=3))\n",
    "triangles = np.array(igraph_g_original.vs['_nx_name'])[triangles_ids_igraph_original]\n",
    "print(\"triangles shape : \", triangles.shape)\n",
    "print(triangles[0])\n",
    "\n",
    "# Calculate barycenters\n",
    "b = np.mean(triangles, axis=1)\n",
    "print(\"shape b : \", b.shape)\n",
    "print(\"Barycentre b: \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 3)\n",
      "B_HAT :  [[47.          4.6978393  84.784485  ]\n",
      " [80.31373    -3.4051468  64.        ]\n",
      " [39.         -3.5383415   2.003548  ]\n",
      " ...\n",
      " [87.31728    -7.6234546  59.7       ]\n",
      " [82.77744    -5.8180504  59.7       ]\n",
      " [39.          0.11193975 86.07437   ]]\n"
     ]
    }
   ],
   "source": [
    "# Get finals selected triangles & calculate barycenters\n",
    "b_hat = np.mean(selected_triangles, axis=1)\n",
    "print(b_hat.shape)\n",
    "print(\"B_HAT : \", b_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test matrice des normes euclidiennes entre b et b_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 11994)\n",
      "Distances euclidiennes entre les barycentres b et b_hat :\n",
      " [[8074.10967357 6646.91326676 7910.41073963 ... 4887.40768797\n",
      "  6691.11455262 4353.73076529]\n",
      " [6286.82023725 4292.9621672  5129.72869552 ... 1882.71249962\n",
      "  3162.00778693 1532.76126903]\n",
      " [ 215.58637901  280.05204622  303.89222732 ... 1667.65387959\n",
      "  1344.03504688 1849.198191  ]\n",
      " ...\n",
      " [6405.28333268 4252.15683593 4951.99979399 ... 1692.67609932\n",
      "  2866.29983319 1381.86322316]\n",
      " [5967.48696517 3951.27213778 4685.66126172 ... 1581.09066803\n",
      "  2752.32691079 1269.28933677]\n",
      " [8365.70756894 7037.26310361 8229.87057224 ... 5535.827756\n",
      "  7377.19845763 4992.74929551]]\n"
     ]
    }
   ],
   "source": [
    "distances = matrix_distance_euclidienne_barycentres(b, b_hat)\n",
    "print(distances.shape)\n",
    "print(\"Distances euclidiennes entre les barycentres b et b_hat :\\n\", distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "[ 3.15451224 15.37948972  0.53263409 15.09775702  0.06572607]\n"
     ]
    }
   ],
   "source": [
    "minimums_b = np.min(distances, axis=1)\n",
    "print(minimums_b.shape)\n",
    "print(minimums_b[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85941036.95043153\n"
     ]
    }
   ],
   "source": [
    "d_f_S_Ss = np.sum(selected_triangles_indexes * minimums_b)\n",
    "print(d_f_S_Ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triangle Collision Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lc_le_lo(p_t, m_c_e_o, Fs):\n",
    "    \"\"\"\n",
    "    Compute the collision loss term L_c.\n",
    "\n",
    "    Parameters:\n",
    "    - p_t: 1D numpy array containing the probabilities of each triangle (indices)\n",
    "    - m_c_t: 2D numpy array containing the number of faces penetrated by each triangle\n",
    "    - Fs: 3D numpy array representing the vertices of triangles\n",
    "\n",
    "    Returns:\n",
    "    - L_c: Collision loss term\n",
    "    \"\"\"\n",
    "    assert len(p_t) == len(m_c_e_o), \"Input arrays must have the same length\"\n",
    "\n",
    "    penalty_per_triangle = p_t * m_c_e_o\n",
    "\n",
    "    # Sum the penalties for all selected triangles\n",
    "    total_penalty = np.sum(penalty_per_triangle)\n",
    "\n",
    "    # Compute the collision loss term L_c\n",
    "    L_c_e_o = (1 / len(Fs)) * total_penalty\n",
    "\n",
    "    return L_c_e_o\n",
    "\n",
    "# Example usage:\n",
    "# Replace the arrays below with your actual data\n",
    "# p_t = selected_triangles_indexes\n",
    "# m_c_t = numpy array containing the number of faces penetrated by each triangle\n",
    "# Fs = 3D numpy array representing the vertices of triangles\n",
    "p_t = selected_triangles_indexes\n",
    "Fs = triangles  # Given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_neigh_selected_barycenters = min(50, len(b_hat))\n",
    "_, indexes_neigh_selected_barycenters = NearestNeighbors(n_neighbors=number_neigh_selected_barycenters).fit(b_hat).kneighbors(b_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_c :  2578.897948974487\n"
     ]
    }
   ],
   "source": [
    "mc = np.zeros((500))\n",
    "\n",
    "for index_neigh_barycenters in indexes_neigh_selected_barycenters:\n",
    "    current_triangle = selected_triangles[index_neigh_barycenters[0]]\n",
    "    others_triangles = selected_triangles[index_neigh_barycenters[1:]]\n",
    "\n",
    "    lines_current_triangle = LinearRing(current_triangle)\n",
    "    polygons_others_tri = MultiPolygon([Polygon(others_triangle) for others_triangle in others_triangles]).buffer(0)    # buffer 0 to correct invalid polygons => take the exterior of the shape\n",
    "\n",
    "\n",
    "    intersection = lines_current_triangle.intersection(polygons_others_tri)\n",
    "    if intersection.is_empty:\n",
    "        continue\n",
    "    if intersection.geom_type == 'MultiLineString':\n",
    "        mc[index_neigh_barycenters[0]] = len(intersection.geoms)\n",
    "    else:\n",
    "        mc[index_neigh_barycenters[0]] += 1\n",
    "L_c = compute_lc_le_lo(p_t, mc, Fs)\n",
    "print(\"L_c : \", L_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_e :  12267.803151575788\n"
     ]
    }
   ],
   "source": [
    "me = np.zeros((500))\n",
    "\n",
    "for index_neigh_barycenters in indexes_neigh_selected_barycenters:\n",
    "    current_triangle = selected_triangles[index_neigh_barycenters[0]]\n",
    "    others_triangles = selected_triangles[index_neigh_barycenters[1:]]\n",
    "\n",
    "    lines_current_triangle = LinearRing(current_triangle)\n",
    "    lines_others_tri = MultiLineString([LineString([other_tri[0], other_tri[1], other_tri[2], other_tri[0]]) for other_tri in others_triangles])\n",
    "\n",
    "    intersection = lines_current_triangle.intersection(lines_others_tri)\n",
    "    if intersection.is_empty:\n",
    "        continue\n",
    "    if intersection.geom_type == 'MultiLineString':\n",
    "        me[index_neigh_barycenters[0]] = len(intersection.geoms)\n",
    "    else:\n",
    "        me[index_neigh_barycenters[0]] += 1\n",
    "L_e = compute_lc_le_lo(p_t, me, Fs)\n",
    "print(\"L_e : \", L_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igraph_g = igraphGraph(directed=extended_graph.is_directed()).from_networkx(extended_graph)\n",
    "print(igraph_g.summary())\n",
    "\n",
    "triangles_ids_igraph = np.array(igraph_g.cliques(min=3, max=3))\n",
    "print(\" IDS TRI\", triangles_ids_igraph[:3])\n",
    "print(len(triangles_ids_igraph))\n",
    "\n",
    "\n",
    "triangles = np.array(igraph_g.vs['_nx_name'])[triangles_ids_igraph]   #les triangles\n",
    "# triangles = [list(map(tuple, row)) for row in triangles.tolist()]\n",
    "print(\"TRI\",triangles)\n",
    "print(len(triangles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sample_points_from_triangle(triangle, num_points=100):\n",
    "    v1, v2, v3 = triangle\n",
    "    bary_coords = np.random.rand(num_points, 2)\n",
    "    sqrt_bary_coords = np.sqrt(bary_coords[:, 0])\n",
    "\n",
    "    u = sqrt_bary_coords\n",
    "    v = bary_coords[:, 1]\n",
    "\n",
    "    \"\"\"\n",
    "    La formule spÃ©cifique est dÃ©rivÃ©e de l'expression gÃ©nÃ©rale d'interpolation barycentrique \n",
    "    sommets A, B et C\n",
    "    coord barycentriques: u et v\n",
    "    coord cartÃ©siennes: x,y,z \n",
    "    \"\"\"\n",
    "    x_coords = (1 - u - v) * v1[0] + u * v2[0] + v * v3[0]\n",
    "    y_coords = (1 - u - v) * v1[1] + u * v2[1] + v * v3[1]\n",
    "    z_coords = (1 - u - v) * v1[2] + u * v2[2] + v * v3[2]\n",
    "\n",
    "    sampled_points = np.column_stack((x_coords, y_coords, z_coords))\n",
    "    return sampled_points\n",
    "\n",
    "\n",
    "\"\"\"\"\n",
    "\n",
    "Calcul des distances : Ces points Ã©chantillonnÃ©s sont utilisÃ©s pour calculer leurs distances par rapport aux 50 triangles les plus proches.\n",
    "Objectif d'appartenance : L'objectif est d'attribuer chaque point Ã©chantillonnÃ© Ã  un seul triangle. \n",
    "Pour dÃ©terminer cette appartenance, nous mesurons les aires A1, A2, A3 en remplaÃ§ant chaque sommet du triangle par le point de requÃªte. \n",
    "Ensuite, nous vÃ©rifions si la somme de ces trois aires est Ã©gale Ã  l'aire du triangle.\n",
    "Prise en compte des plans parallÃ¨les : Pour les triangles partageant des plans parallÃ¨les, \n",
    "nous ajustons lÃ©gÃ¨rement la tolÃ©rance de distance sur l'axe vertical par rapport au plan du triangle.\n",
    "Application de la pÃ©nalitÃ© : Enfin, une pÃ©nalitÃ© est appliquÃ©e Ã  tous les triangles partageant un point Ã©chantillonnÃ©. \n",
    "Cette pÃ©nalitÃ©, similaire Ã  la perte de croisement d'arÃªtes (Edge Crossing), est proportionnelle au nombre de triangles qui se chevauchent.\n",
    "\n",
    "\"\"\"\n",
    "# PrÃ©lÃ¨vement de 100 points de chaque triangle\n",
    "sampled_points_list = [sample_points_from_triangle(triangle, num_points=100) for triangle in triangles]\n",
    "\n",
    "# Affichage des points Ã©chantillonnÃ©s pour le premier triangle (vous pouvez boucler pour afficher pour tous les triangles)\n",
    "print(\"Points Ã©chantillonnÃ©s pour le premier triangle :\")\n",
    "print(sampled_points_list[0])\n",
    "\n",
    "# Convertir les triangles en une liste plate pour faciliter la recherche\n",
    "flat_triangles = np.vstack(triangles)\n",
    "\n",
    "sampled_points_flat = np.vstack(sampled_points_list)\n",
    "\n",
    "# SÃ©lection des coordonnÃ©es x, y, et z des triangles\n",
    "flat_triangles_xyz = flat_triangles[:, :3]\n",
    "\n",
    "#modÃ¨le k-NN\n",
    "knn_model = NearestNeighbors(n_neighbors=50, algorithm='auto').fit(flat_triangles_xyz)\n",
    "\n",
    "# Recherche des indices des triangles les plus proches pour chaque point Ã©chantillonnÃ©\n",
    "distances, indices = knn_model.kneighbors(sampled_points_flat)\n",
    "\n",
    "# Initialisation des variables pour stocker les rÃ©sultats\n",
    "assignment_results = []\n",
    "\n",
    "# Calcul des distances par rapport aux 50 triangles les plus proches\n",
    "for i, point in enumerate(sampled_points_list):\n",
    "    closest_triangle_indices = indices[i]\n",
    "    closest_triangles = flat_triangles[closest_triangle_indices]\n",
    "\n",
    "    # Calcul des aires et dÃ©termination de l'appartenance au triangle\n",
    "    for triangle in closest_triangles:\n",
    "        # Remplacer chaque sommet du triangle par le point de requÃªte\n",
    "        modified_triangle = np.copy(triangle)\n",
    "        modified_triangle[0] = point\n",
    "\n",
    "        # Calcul des aires A1, A2, A3\n",
    "        area_original = calculate_triangle_area(triangle)\n",
    "        area_modified = calculate_triangle_area(modified_triangle)\n",
    "\n",
    "        # VÃ©rification si la somme des aires est Ã©gale Ã  l'aire du triangle\n",
    "        if np.isclose(area_original, area_modified, rtol=1e-5):\n",
    "            assignment_results.append((point, triangle))\n",
    "            break  # On attribue le point au premier triangle vÃ©rifiÃ©\n",
    "\n",
    "# Prise en compte des plans parallÃ¨les et ajustement de la tolÃ©rance (Ã  implÃ©menter)\n",
    "\n",
    "# Application de la pÃ©nalitÃ© pour les triangles se chevauchant (Ã  implÃ©menter)\n",
    "\n",
    "# Affichage des rÃ©sultats (Ã  remplacer par le traitement final souhaitÃ©)\n",
    "for point, triangle in assignment_results:\n",
    "    print(f\"Point {point} attribuÃ© au triangle {triangle}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = np.zeros((500))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meshPFE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
