{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Transformation import Transformation\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import networkx as nx\n",
    "import torch\n",
    "from numpy import mean\n",
    "from igraph import Graph as igraphGraph\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import scipy.spatial.distance\n",
    "from scipy.spatial.distance import cdist\n",
    "from shapely.geometry import LineString, MultiLineString, Polygon, MultiPolygon, LinearRing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 5999\n",
      "Number of edges: 17991\n"
     ]
    }
   ],
   "source": [
    "transformation = Transformation()\n",
    "\n",
    "user_number_triangles = 500   #à diminuer si le process est trop long\n",
    "number_neigh_tri = 20\n",
    "\n",
    "# Create objects\n",
    "stl_file_path = \"3d_models/stl/Handle.stl\"\n",
    "mesh_data = transformation.stl_to_mesh(stl_file_path)\n",
    "graph = transformation.mesh_to_graph(mesh_data)\n",
    "\n",
    "transformation.print_graph_properties(graph, display_graph=False, display_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(graph._node)<20:\n",
    "    raise Exception(\"Input mesh does not have enough vertices. (More than 20 is needed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DevConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(array):\n",
    "    return np.maximum(array, 0)\n",
    "\n",
    "def sigmoid(array):\n",
    "    return 1 / (1 + np.exp(-array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DevConv():\n",
    "    def __init__(self, graph, output_dimension):\n",
    "        self.graph = graph\n",
    "        self.list_node = list(graph._node)\n",
    "\n",
    "        self.W_phi = np.random.random((output_dimension))      #change\n",
    "        self.W_theta = np.array([0.1, 0.1, 0.1]).reshape(1, -1)  # change\n",
    "    \n",
    "    def forward(self, previous_inclusion_score, return_flatten=True):\n",
    "        list_inc_score = np.zeros((len(self.list_node), len(self.W_phi)))                               #list of \"output_dimension\" for each \"list_node\" element\n",
    "        for index_current_node, (current_node, dict_neigh) in enumerate(self.graph._adj.items()):       # for each node and its adjacency nodes\n",
    "            neigh_nodes = np.array(list(dict_neigh.keys()))                                             # array of adjacency nodes\n",
    "            diff = current_node - neigh_nodes                                                           # Compute the differences between current_node and all neighbor nodes   (x_i - x_j)\n",
    "            neigh_distances = np.linalg.norm(self.W_theta * diff, axis=1)                               # Compute the norm for each vector difference  ||W_theta * (x_i - x_j)||\n",
    "            list_inc_score[index_current_node] = self.W_phi * np.max(neigh_distances)                   # Add (W_phi * ||W_theta * (x_i - x_j)||) to the inclusion score list\n",
    "\n",
    "        if len(previous_inclusion_score)==0:                            # return if no previous inclusion score\n",
    "            if return_flatten:\n",
    "                list_inc_score = list_inc_score.flatten()\n",
    "            return list_inc_score\n",
    "        \n",
    "        if list_inc_score.shape[1]!=1:                                  # If inclusion score is not vector\n",
    "            list_inc_score = np.mean(list_inc_score, axis=1)            # Mean the matrix for each node\n",
    "\n",
    "        # array of array to array\n",
    "        if len(list_inc_score.shape)==2:                 \n",
    "            if list_inc_score.shape[1]==1:\n",
    "                list_inc_score = list_inc_score.flatten()\n",
    "\n",
    "        # Return the mean of previous and current inclusion score\n",
    "        return np.mean(np.array([previous_inclusion_score, list_inc_score], dtype=np.float64), axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40147705 0.40171063 0.40147705 ... 0.37376161 0.54254544 0.37376161]\n",
      "[0.56322676 0.56355445 0.56322676 ... 0.52434514 0.7611297  0.52434514]\n",
      "[0.6078138  0.60787456 0.6078138  ... 0.60058087 0.6438422  0.60058087]\n",
      "(5999,)\n"
     ]
    }
   ],
   "source": [
    "devconv = DevConv(graph, 1)\n",
    "inclusion_score = devconv.forward(previous_inclusion_score=np.array([]))\n",
    "inclusion_score = relu(inclusion_score)\n",
    "print(inclusion_score)\n",
    "\n",
    "devconv = DevConv(graph, 64)\n",
    "inclusion_score = devconv.forward(previous_inclusion_score=inclusion_score)\n",
    "inclusion_score = relu(inclusion_score)\n",
    "print(inclusion_score)\n",
    "\n",
    "devconv = DevConv(graph, 1)\n",
    "inclusion_score = devconv.forward(previous_inclusion_score=inclusion_score)\n",
    "inclusion_score = sigmoid(inclusion_score)\n",
    "print(inclusion_score)\n",
    "print(inclusion_score.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "normalized_inclusion_score = inclusion_score / np.sum(inclusion_score)  # normalize for multinomial sampling\n",
    "normalized_inclusion_score = np.round(normalized_inclusion_score, 8)    # round to remove float imprecision\n",
    "\n",
    "number_throws = 500     # small:more randomness    |   big:less randomness\n",
    "mult_sampling = np.random.multinomial(number_throws, normalized_inclusion_score)\n",
    "print(mult_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[75.53     ,  6.9390492, 84.5463   ],\n",
       "       [79.42433  ,  2.9401166, 97.711845 ],\n",
       "       [91.70368  ,  2.3044074, 85.675735 ],\n",
       "       [92.19819  ,  2.3044074, 83.0076   ],\n",
       "       [80.28243  ,  2.9401166, 97.457664 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_number_point = min(len(graph._node), user_number_triangles*3)   # number of points for the simplification\n",
    "\n",
    "index_k_nodes = np.argpartition(mult_sampling, -target_number_point)[-target_number_point:]     # Take the k (\"target_number_points\") largest values given by the multinomial sampling \n",
    "list_k_nodes = np.array(graph)[index_k_nodes]                                # Take the selected nodes (list of list of 3)\n",
    "list_k_nodes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN extended graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n_, indices = NearestNeighbors(n_neighbors=15).fit(list_k_nodes).kneighbors(list_k_nodes)        # KNN of the selected points\\n\\nextended_graph = nx.Graph()\\nfor index_poly, poly in enumerate(indices):                                 # For the neighbors of the 'index_poly' node\\n    current_node = tuple(list_k_nodes[poly[0]])                             # Tuple of the main node coordinates\\n    for index_other_node in poly[1:]:                                       # For every neighbors of the main node (main node is the first index)\\n        edge = current_node, tuple(list_k_nodes[index_other_node])          # Create an edge of two tuples\\n        extended_graph.add_edge(*edge)                                      # Add the edge to the graph\\n\\ntransformation.print_graph_properties(graph=extended_graph, display_graph=False, display_labels=False)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "_, indices = NearestNeighbors(n_neighbors=15).fit(list_k_nodes).kneighbors(list_k_nodes)        # KNN of the selected points\n",
    "\n",
    "extended_graph = nx.Graph()\n",
    "for index_poly, poly in enumerate(indices):                                 # For the neighbors of the 'index_poly' node\n",
    "    current_node = tuple(list_k_nodes[poly[0]])                             # Tuple of the main node coordinates\n",
    "    for index_other_node in poly[1:]:                                       # For every neighbors of the main node (main node is the first index)\n",
    "        edge = current_node, tuple(list_k_nodes[index_other_node])          # Create an edge of two tuples\n",
    "        extended_graph.add_edge(*edge)                                      # Add the edge to the graph\n",
    "\n",
    "transformation.print_graph_properties(graph=extended_graph, display_graph=False, display_labels=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 1500\n",
      "Number of edges: 11787\n"
     ]
    }
   ],
   "source": [
    "def knn_and_extended_graph(list_k_nodes_i, k_neighbors=15):\n",
    "    \"\"\"\n",
    "    Perform k-NN on the given points and construct an extended graph.\n",
    "\n",
    "    Parameters:\n",
    "    - list_k_nodes_i: array-like\n",
    "        List of coordinates of the selected points.\n",
    "    - k_neighbors: int, optional (default=15)\n",
    "        Number of neighbors for k-NN.\n",
    "\n",
    "    Returns:\n",
    "    - extended_graph_i: networkx.Graph\n",
    "        Extended graph.\n",
    "    \"\"\"\n",
    "\n",
    "    # Perform k-NN on the selected points\n",
    "    _, indices = NearestNeighbors(n_neighbors=k_neighbors).fit(list_k_nodes_i).kneighbors(list_k_nodes_i)\n",
    "\n",
    "    # Construct the extended graph\n",
    "    extended_graph_i = nx.Graph()\n",
    "    for poly in indices:\n",
    "        current_node = tuple(list_k_nodes_i[poly[0]])\n",
    "        for index_other_node in poly[1:]:\n",
    "            edge = current_node, tuple(list_k_nodes_i[index_other_node])\n",
    "            extended_graph_i.add_edge(*edge)\n",
    "\n",
    "    return extended_graph_i\n",
    "\n",
    "extended_graph = knn_and_extended_graph(list_k_nodes)\n",
    "transformation.print_graph_properties(graph=extended_graph, display_graph=False, display_labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devconv = DevConv(extended_graph, 64)\n",
    "inclusion_score = devconv.forward(previous_inclusion_score=np.array([]), return_flatten=False)\n",
    "inclusion_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "inclusion_score = [[f_1_1  , f_1_2  , ..., f_63_1  ],\n",
    "                    ...,\n",
    "                   [f_1_M-1, f_1_M-1, ..., f_63_M-1]]\n",
    "M = number of points\n",
    "64 = hidden dimensions\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "f = np.mean(inclusion_score, axis=1)                            # Flatten the matrix of inclusion score \n",
    "wq = np.random.rand(64)\n",
    "wk = np.random.rand(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wq_f = wq.reshape(-1, 1) * f            # Wq*f\n",
    "wk_f = wk.reshape(-1, 1) * f            # Wq*f\n",
    "S = np.exp(np.dot(wq_f.T, wk_f))        # e^((wq_f.T)*(wk_f))\n",
    "\n",
    "nodes = list(extended_graph.nodes())                                                                                # list of nodes\n",
    "node_indices = {node: index for index, node in enumerate(nodes)}                                                    # dict{node: index}\n",
    "neighbors_indices = [[node_indices[neighbor] for neighbor in extended_graph.neighbors(node)] for node in nodes]     # List of list : [[neigh1 of node1, neigh2 of node1...], [neigh1 of node2, neigh2 of node2...]...]\n",
    "\n",
    "\n",
    "for index_current_node, neighbors_index in enumerate(neighbors_indices):        # For each neighbors of the 'index_current_node' node\n",
    "    sum_columns = np.sum(S[:, neighbors_index], axis=1)                         # Sum along the rows the values of the neighbors\n",
    "    S[index_current_node] = S[index_current_node] / sum_columns                 # And divide the current node columns by the sume of the neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S = S*np.random.choice([0, 1], size=S.shape)      # Add a random mask to emulate the 'sparse'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 206)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 10)\t1\n",
      "  :\t:\n",
      "  (1498, 1350)\t1\n",
      "  (1498, 1351)\t1\n",
      "  (1498, 1352)\t1\n",
      "  (1498, 1375)\t1\n",
      "  (1498, 1376)\t1\n",
      "  (1498, 1377)\t1\n",
      "  (1498, 1378)\t1\n",
      "  (1498, 1379)\t1\n",
      "  (1498, 1489)\t1\n",
      "  (1498, 1497)\t1\n",
      "  (1499, 1123)\t1\n",
      "  (1499, 1130)\t1\n",
      "  (1499, 1132)\t1\n",
      "  (1499, 1134)\t1\n",
      "  (1499, 1135)\t1\n",
      "  (1499, 1136)\t1\n",
      "  (1499, 1477)\t1\n",
      "  (1499, 1478)\t1\n",
      "  (1499, 1479)\t1\n",
      "  (1499, 1486)\t1\n",
      "  (1499, 1488)\t1\n",
      "  (1499, 1491)\t1\n",
      "  (1499, 1492)\t1\n",
      "  (1499, 1493)\t1\n",
      "  (1499, 1494)\t1\n",
      "[[5.07211670e-02 3.73747488e-04 5.58821227e-02 ... 2.37675621e-02\n",
      "  2.52617178e-02 7.74926068e-03]\n",
      " [3.58486238e+00 1.61332339e-04 7.86334379e-02 ... 5.20420470e-02\n",
      "  5.57974983e-02 1.14365630e-02]\n",
      " [1.61900578e+00 3.80793390e-01 4.94116686e-02 ... 2.11740861e-02\n",
      "  2.25090413e-02 6.77898492e-03]\n",
      " ...\n",
      " [3.21066401e+00 9.41049622e+00 3.35916362e+00 ... 6.93250520e-02\n",
      "  6.92117334e-02 7.11619220e-02]\n",
      " [3.41553994e+00 9.28685721e+00 3.58477007e+00 ... 1.51510362e-01\n",
      "  7.20553943e-02 7.23881510e-02]\n",
      " [1.30627608e+01 1.95322561e+02 1.32238424e+01 ... 2.66689030e+00\n",
      "  2.86004477e+00 3.07494511e-02]]\n"
     ]
    }
   ],
   "source": [
    "adjacency = nx.adjacency_matrix(extended_graph)\n",
    "# S = np.random.rand(target_number_point, target_number_point)\n",
    "print(adjacency)\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_s = np.zeros((target_number_point,target_number_point))   # Init A_s to 0\n",
    "A_s = np.matmul(np.matmul(S, adjacency.toarray()), S.T)     # A_s = S * A * S.T\n",
    "A_s = A_s/A_s.max()                                         # Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.68900149e-32 2.98323689e-32 1.54712026e-32 ... 5.95647877e-31\n",
      "  6.16730617e-31 2.91148885e-30]\n",
      " [2.98323689e-32 5.30633670e-32 2.77844973e-32 ... 1.17584783e-30\n",
      "  1.21345730e-30 7.11460786e-30]\n",
      " [1.54712026e-32 2.77844973e-32 1.47032389e-32 ... 6.10812309e-31\n",
      "  6.28953811e-31 4.04792701e-30]\n",
      " ...\n",
      " [5.95647877e-31 1.17584783e-30 6.10812309e-31 ... 7.64333160e-28\n",
      "  6.89017977e-28 1.37711088e-26]\n",
      " [6.16730617e-31 1.21345730e-30 6.28953811e-31 ... 6.89017977e-28\n",
      "  6.22942673e-28 1.22200764e-26]\n",
      " [2.91148885e-30 7.11460786e-30 4.04792701e-30 ... 1.37711088e-26\n",
      "  1.22200764e-26 2.82027353e-25]]\n",
      "(1500, 1500)\n"
     ]
    }
   ],
   "source": [
    "print(A_s)  # symmétrique\n",
    "print(A_s.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TriConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH U--- 1500 11787 -- \n",
      "+ attr: _nx_name (v)\n"
     ]
    }
   ],
   "source": [
    "igraph_g = igraphGraph(directed=extended_graph.is_directed()).from_networkx(extended_graph)\n",
    "print(igraph_g.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 799 1155 1156]\n",
      " [ 796  799 1156]\n",
      " [ 716  741  742]]\n",
      "32966\n"
     ]
    }
   ],
   "source": [
    "triangles_ids_igraph = np.array(igraph_g.cliques(min=3, max=3))\n",
    "print(triangles_ids_igraph[:3])\n",
    "print(len(triangles_ids_igraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[63.        -5.921278  83.49013  ]\n",
      "  [63.        -8.8       90.       ]\n",
      "  [63.        -8.177119  86.74812  ]]\n",
      "\n",
      " [[63.         4.0099483 82.16672  ]\n",
      "  [63.        -5.921278  83.49013  ]\n",
      "  [63.        -8.177119  86.74812  ]]\n",
      "\n",
      " [[76.83412   -5.5423326  3.0959466]\n",
      "  [76.16304   -5.0095077  2.7527924]\n",
      "  [76.30896   -6.0434117  1.7843841]]]\n",
      "32966\n"
     ]
    }
   ],
   "source": [
    "triangles = np.array(igraph_g.vs['_nx_name'])[triangles_ids_igraph]   #les triangles\n",
    "# triangles = [list(map(tuple, row)) for row in triangles.tolist()]\n",
    "print(triangles[:3])\n",
    "print(len(triangles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32966,)\n",
      "[1.02927782e-01 2.16026675e-06 3.89184545e-25 ... 3.02231769e-28\n",
      " 3.42448826e-25 1.27181109e-25]\n"
     ]
    }
   ],
   "source": [
    "# Extract indices for each triangle\n",
    "i, j, k = triangles_ids_igraph.T\n",
    "\n",
    "# Extract probabilities using advanced indexing\n",
    "A_s_ij = A_s[i, j]\n",
    "A_s_ik = A_s[i, k]\n",
    "A_s_jk = A_s[j, k]\n",
    "\n",
    "# Calculate the barycenter probabilities\n",
    "p_init = np.zeros(len(triangles))\n",
    "p_init = (A_s_ij + A_s_ik + A_s_jk) / 3\n",
    "\n",
    "print(p_init.shape)\n",
    "print(p_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate barycenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32966, 3)\n",
      "[[63.        -7.632799  86.746086 ]\n",
      " [63.        -3.3628166 84.13499  ]\n",
      " [76.43537   -5.53175    2.5443742]]\n"
     ]
    }
   ],
   "source": [
    "barycenters = np.mean(triangles, axis=1)\n",
    "print(barycenters.shape)\n",
    "print(barycenters[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Tri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, indices_neigh_tri = NearestNeighbors(n_neighbors=number_neigh_tri).fit(barycenters).kneighbors(barycenters)          # Find k='number_neigh_tri' neighbors of each triangles based on theirs barycenters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diff Barycenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32966, 19, 3)\n"
     ]
    }
   ],
   "source": [
    "# Calculates the difference between each barycenters and their n='number_neigh_tri'-1 neighbors\n",
    "barycenters_diff = np.subtract(barycenters[indices_neigh_tri[:, 0]][:, np.newaxis], barycenters[indices_neigh_tri[:, 1:]])   #Inverser la différence des barycentres si nécéssaire\n",
    "\n",
    "print(barycenters_diff.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate e norm matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32966, 3)\n",
      "[[ 7.117969   3.962746   3.3109944]\n",
      " [10.019015  13.01975    3.962746 ]]\n"
     ]
    }
   ],
   "source": [
    "diff_vectors = list()\n",
    "\n",
    "for triangle in triangles:\n",
    "    e_ij = np.linalg.norm(np.array(triangle[0]) - np.array(triangle[1]))    #Calculate the vectors for each edge of each triangles\n",
    "    e_ik = np.linalg.norm(np.array(triangle[0]) - np.array(triangle[2]))\n",
    "    e_jk = np.linalg.norm(np.array(triangle[1]) - np.array(triangle[2]))\n",
    "    diff_vectors.append([e_ij, e_ik, e_jk])\n",
    "\n",
    "diff_vectors = np.array(diff_vectors)\n",
    "print(diff_vectors.shape)\n",
    "print(diff_vectors[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32966,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_diff_vectors = diff_vectors.max(axis=1)       # calculate t_n_max\n",
    "min_diff_vectors = diff_vectors.min(axis=1)       # calculate t_n_min\n",
    "max_diff_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32966, 19)\n",
      "(32966, 19)\n"
     ]
    }
   ],
   "source": [
    "max_diff_vectors_diff = np.subtract(max_diff_vectors[indices_neigh_tri[:, 0]][:, np.newaxis], max_diff_vectors[indices_neigh_tri[:, 1:]])   #Inverser la différence des barycentres si nécéssaire   # calculate t_n_max - t_m_max\n",
    "print(max_diff_vectors_diff.shape)\n",
    "min_diff_vectors_diff = np.subtract(min_diff_vectors[indices_neigh_tri[:, 0]][:, np.newaxis], min_diff_vectors[indices_neigh_tri[:, 1:]])   #Inverser la différence des barycentres si nécéssaire   # calculate t_n_min - t_m_min\n",
    "print(min_diff_vectors_diff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32966, 19, 5)\n"
     ]
    }
   ],
   "source": [
    "r_matrix = np.zeros((len(triangles), number_neigh_tri-1, 5))\n",
    "\n",
    "r_matrix[:, :, 0]   = min_diff_vectors_diff\n",
    "r_matrix[:, :, 1]   = max_diff_vectors_diff\n",
    "r_matrix[:, :, 2:5] = barycenters_diff\n",
    "\n",
    "print(r_matrix.shape)  # nb_triangles, len(indices_neigh_tri), 5dim/triangles\n",
    "\n",
    "# Here r_matrix[i,j] represent the relation between the triangles (n = i) and (m = indices_neigh_tri_array[i,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999998208\n",
      "(32966,)\n",
      "[3.36129308e-05 3.03253870e-05 3.03253215e-05 ... 3.03253215e-05\n",
      " 3.03253215e-05 3.03253215e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arthur\\AppData\\Local\\Temp\\ipykernel_14788\\474768578.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  final_scores = torch.nn.functional.softmax(torch.tensor(f_final))    #proba des triangles\n"
     ]
    }
   ],
   "source": [
    "# Multi Layer Perceptron (MLP) * 3 \n",
    "f_final = p_init    # TODO\n",
    "\n",
    "\n",
    "final_scores = torch.nn.functional.softmax(torch.tensor(f_final))    #proba des triangles\n",
    "final_scores = final_scores.numpy()\n",
    "print(final_scores.sum())\n",
    "print(final_scores.shape)\n",
    "print(final_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 3, 3)\n",
      "[[90.93887    5.145526  16.7      ]\n",
      " [89.843414  -6.3966537 29.6      ]\n",
      " [79.06786    7.4193583 29.6      ]]\n"
     ]
    }
   ],
   "source": [
    "selected_triangles_indexes = np.argpartition(final_scores, -int(target_number_point/3))[-int(target_number_point/3):] \n",
    "selected_triangles = np.array(triangles)[selected_triangles_indexes]\n",
    "print(selected_triangles.shape) # number triangles, number points, number dimensions(x,y,z)\n",
    "print(selected_triangles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 43\n",
      "Number of edges: 192\n"
     ]
    }
   ],
   "source": [
    "simplified_final_graph = nx.Graph()\n",
    "for index_poly, poly in enumerate(selected_triangles):\n",
    "    for index_current_node in range(len(poly)):\n",
    "        current_node = tuple(poly[index_current_node])\n",
    "        for index_other_node in range(index_current_node+1, len(poly)):\n",
    "            edge = current_node, tuple(poly[index_other_node])\n",
    "            simplified_final_graph.add_edge(*edge)\n",
    "            # if attribute do not exists\n",
    "            if len(simplified_final_graph.nodes[current_node])==0:\n",
    "                simplified_final_graph.nodes[current_node]['index_triangle'] = set()\n",
    "            simplified_final_graph.nodes[current_node]['index_triangle'].add(index_poly)\n",
    "            if len(simplified_final_graph.nodes[tuple(poly[index_other_node])])==0:\n",
    "                simplified_final_graph.nodes[tuple(poly[index_other_node])]['index_triangle'] = set()\n",
    "            simplified_final_graph.nodes[tuple(poly[index_other_node])]['index_triangle'].add(index_poly)\n",
    "            \n",
    "transformation.print_graph_properties(graph=simplified_final_graph, display_graph=False, display_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_final_mesh = transformation.graph_to_mesh(simplified_final_graph)\n",
    "\n",
    "#Affichage\n",
    "transformation.mesh_to_display_vtk(mesh_data)\n",
    "transformation.mesh_to_display_vtk(simplified_final_mesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Chamfer distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des points de l'espace de départ P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les points avant K-NN :  [[75.0252     -0.66553295  3.8       ]\n",
      " [75.01418    -0.49935842 16.7       ]\n",
      " [75.          0.          3.8       ]\n",
      " ...\n",
      " [51.         -8.57404    -6.9813724 ]\n",
      " [39.         -8.699333   -6.327254  ]\n",
      " [51.         -8.699333   -6.327254  ]]\n",
      "dim points avant K-NN :  5999\n"
     ]
    }
   ],
   "source": [
    "keys_input = np.array(graph)\n",
    "print(\"Les points avant K-NN : \", keys_input)\n",
    "print(\"dim points avant K-NN : \", len(keys_input))  #return 5999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des points de l'espace de départ Ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled points :  [[75.53       6.9390492 84.5463   ]\n",
      " [75.35414    6.9390492 84.56945  ]\n",
      " [75.70441    6.9390492 84.51398  ]\n",
      " ...\n",
      " [82.64818   -8.672658  88.08646  ]\n",
      " [83.6313    -8.672658  86.80523  ]\n",
      " [85.40667    7.5075808 -4.627157 ]]\n",
      "dim sample points :  1500\n"
     ]
    }
   ],
   "source": [
    "keys_output = np.array(extended_graph)\n",
    "print(\"sampled points : \", keys_output)\n",
    "print(\"dim sample points : \", len(keys_output))  #return: 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squared Euclidean Distances Matrix Shape: (1500, 5999)\n",
      "Distances Matrix:\n",
      " [[ 6578.04991504  4658.71667386  6568.39672594 ...  9219.69210951\n",
      "   9837.00310766  9104.28313695]\n",
      " [ 6581.64199484  4661.70767119  6571.97994256 ...  9215.33328944\n",
      "   9828.393424    9099.89403435]\n",
      " [ 6573.03709129  4654.54169722  6563.39269231 ...  9222.36262614\n",
      "   9843.90170504  9106.99594332]\n",
      " ...\n",
      " [ 7226.43057134  5221.10674005  7237.91634792 ... 10039.50894773\n",
      "  10819.11282119  9915.55654678]\n",
      " [ 7028.04712285  5055.80061497  7039.58244865 ...  9860.73821686\n",
      "  10665.61320983  9738.46196472]\n",
      " [  245.59167916   626.96251933   235.6795192  ...  1447.97978252\n",
      "   2419.13337311  1449.37330231]]\n"
     ]
    }
   ],
   "source": [
    "def matrix_distance_euclidienne_barycentres(barycentre_b, barycentre_b_hat):\n",
    "    \"\"\"\n",
    "    Calculate distances between 2 set of points\n",
    "\n",
    "    Parameters:\n",
    "    - b_hat: array-like, shape (M, 3)\n",
    "        Barycenters after k-NN.\n",
    "    - number_neigh: int, optional (default=3)\n",
    "        Number of neighbors for k-NN.\n",
    "\n",
    "    Returns:\n",
    "    - distances_after: array-like, shape (M, M)\n",
    "        Matrix of distances between barycenters after the k-NN process.\n",
    "    \"\"\"\n",
    "    return cdist(barycentre_b, barycentre_b_hat, metric='sqeuclidean').T\n",
    "\n",
    "distances_matrix = matrix_distance_euclidienne_barycentres(keys_input, keys_output)\n",
    "print(\"Squared Euclidean Distances Matrix Shape:\", distances_matrix.shape)\n",
    "print(\"Distances Matrix:\\n\", distances_matrix)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le min des x de distances_matrix\n",
    "def min_pour_x_list(distances_matrix, x_in):\n",
    "    return np.min(distances_matrix[:, x_in])\n",
    "\n",
    "# Calculer le min des y de distances_matrix\n",
    "def min_pour_y_list(distances_matrix, y_out):\n",
    "    return np.min(distances_matrix[y_out, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_P_Ps(keys_x, keys_y, p_y):\n",
    "    \"\"\"\n",
    "    Calculate the Probabilistic Chamfer distance between two sets of points.\n",
    "\n",
    "    Parameters:\n",
    "    - keys_x (list): The input vertex set, a list of tuples.\n",
    "    - keys_y (list): The sampled points, a list of tuples.\n",
    "    - p_y (list): Their respective probabilities, a weight associated with each point in keys_y.\n",
    "\n",
    "    Returns:\n",
    "        chamfer_distance (float): The Probabilistic Chamfer distance between the two sets of points.\n",
    "    \"\"\"\n",
    "    min_for_x = [p_y[i] * min_pour_x_list(distances_matrix, i) for i in range(len(keys_x))]\n",
    "    min_for_y = [p_y[j] * min_pour_y_list(distances_matrix, j) for j in range(len(keys_y))]\n",
    "    \n",
    "    sum_for_y = np.sum(min_for_y)\n",
    "    sum_for_x = np.sum(min_for_x)\n",
    "\n",
    "    chamfer_distance = sum_for_y + sum_for_x\n",
    "    \n",
    "    return chamfer_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBA :  [0.00019197 0.00019199 0.00019197 ... 0.00018968 0.00020335 0.00018968]\n"
     ]
    }
   ],
   "source": [
    "print(\"PROBA : \", normalized_inclusion_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chamfer Distance: 4.255793966009449\n"
     ]
    }
   ],
   "source": [
    "prob_chamfer_dist = d_P_Ps(keys_input, keys_output, normalized_inclusion_score)\n",
    "print(\"Chamfer Distance:\", prob_chamfer_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Surfaces Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d_f_S_Ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH U--- 5999 17991 -- \n",
      "+ attr: _nx_name (v), index_triangle (v)\n",
      "triangles shape :  (11994, 3, 3)\n",
      "[[39.        8.793697 -4.666995]\n",
      " [51.        8.793697 -4.666995]\n",
      " [39.        8.793697 -5.333005]]\n",
      "shape b :  (11994, 3)\n",
      "Barycentre b:  [[43.          8.793697   -4.8889985 ]\n",
      " [55.          1.0515273   3.7313068 ]\n",
      " [55.         -8.515905   -2.804371  ]\n",
      " ...\n",
      " [75.05613    -0.94137865 21.        ]\n",
      " [75.01313    -0.3882971   8.099999  ]\n",
      " [75.03516    -0.72036856 25.300001  ]]\n"
     ]
    }
   ],
   "source": [
    "# Creation igraph\n",
    "igraph_g_original = igraphGraph(directed=extended_graph.is_directed()).from_networkx(graph)\n",
    "print(igraph_g_original.summary())\n",
    "\n",
    "#Find triangles\n",
    "triangles_ids_igraph_original = np.array(igraph_g_original.cliques(min=3, max=3))\n",
    "triangles = np.array(igraph_g_original.vs['_nx_name'])[triangles_ids_igraph_original]\n",
    "print(\"triangles shape : \", triangles.shape)\n",
    "print(triangles[0])\n",
    "\n",
    "# Calculate barycenters\n",
    "b = np.mean(triangles, axis=1)\n",
    "print(\"shape b : \", b.shape)\n",
    "print(\"Barycentre b: \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 3)\n",
      "B_HAT :  [[86.61672    2.0560768 25.300001 ]\n",
      " [81.23691    2.6044734 25.300001 ]\n",
      " [71.33375   -8.525946  88.80524  ]\n",
      " ...\n",
      " [47.        -4.232605  91.3241   ]\n",
      " [55.        -8.294961  87.62905  ]\n",
      " [63.        -7.632799  86.746086 ]]\n"
     ]
    }
   ],
   "source": [
    "# Get finals selected triangles & calculate barycenters\n",
    "b_hat = np.mean(selected_triangles, axis=1)\n",
    "print(b_hat.shape)\n",
    "print(\"B_HAT : \", b_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 11994)\n",
      "Distances euclidiennes entre les barycentres b et b_hat :\n",
      " [[2859.18967864 1465.83481259 1901.23966356 ...  161.12205128\n",
      "   436.45836812  141.84131636]\n",
      " [2411.74332409 1155.99555691 1601.8939027  ...   69.2650992\n",
      "   343.53214384   49.51629803]\n",
      " [9881.38103548 7596.09287683 8659.11168608 ... 4668.93192118\n",
      "  6593.09452021 4107.54241565]\n",
      " ...\n",
      " [9442.64423827 7764.41889398 8942.51511236 ... 5743.45714458\n",
      "  7725.76452932 5157.48698186]\n",
      " [8995.61176704 7126.18836066 8178.25269021 ... 4895.75396666\n",
      "  6787.91079053 4343.69241805]\n",
      " [9066.81852243 7030.87111229 8084.06426836 ... 4512.67320588\n",
      "  6382.00505878 3968.24804145]]\n"
     ]
    }
   ],
   "source": [
    "distances = matrix_distance_euclidienne_barycentres(b, b_hat)\n",
    "print(distances.shape)\n",
    "print(\"Distances euclidiennes entre les barycentres b et b_hat :\\n\", distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "[28.17643517 26.45724819  0.19258887 58.67391697 60.97788051]\n"
     ]
    }
   ],
   "source": [
    "minimums_b = np.min(distances, axis=1)\n",
    "print(minimums_b.shape)\n",
    "print(minimums_b[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188058353.55402204\n"
     ]
    }
   ],
   "source": [
    "d_f_S_Ss = np.sum(selected_triangles_indexes * minimums_b)\n",
    "print(d_f_S_Ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d_r_S_Ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = distances\n",
    "min_d = distances.min(axis=1)\n",
    "min_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_y = np.array(final_scores)[selected_triangles_indexes]\n",
    "p_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_term = p_y * min_d\n",
    "first_term.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_neigh_selected_barycenters = min(50, len(b))\n",
    "_, indexes_neigh_selected_barycenters = NearestNeighbors(n_neighbors=number_neigh_selected_barycenters).fit(b).kneighbors(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,  3197,  3204, ...,  3209,    67,  2784],\n",
       "       [    1,  3307,  2916, ...,  3252,    72,    71],\n",
       "       [    2,  2978,  3427, ...,    81,  3300,  3297],\n",
       "       ...,\n",
       "       [11991, 11988, 11165, ..., 11201, 11355, 11365],\n",
       "       [11992,  2563,  2966, ...,  6500,  6502,  6495],\n",
       "       [11993,  2965,  2564, ...,  2576, 11359, 11195]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_neigh_selected_barycenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(587706, 3)\n",
      "(500, 3)\n"
     ]
    }
   ],
   "source": [
    "xt = b[indexes_neigh_selected_barycenters[:, 1:]].reshape((len(b)*(number_neigh_selected_barycenters-1),3))\n",
    "print(xt.shape)\n",
    "\n",
    "y = b_hat\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(587706, 500)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances_barycenter_knn = cdist(xt, y, metric='sqeuclidean')\n",
    "distances_barycenter_knn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(587706,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt = final_scores[indexes_neigh_selected_barycenters[:, 1:]].reshape((len(b)*(number_neigh_selected_barycenters-1)))\n",
    "pt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 587706)\n",
      "(500,)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "ptk_norm = pt*distances_barycenter_knn.T\n",
    "print(ptk_norm.shape)\n",
    "\n",
    "sum_ptk_norm = np.sum(ptk_norm, axis=1)\n",
    "print(sum_ptk_norm.shape)\n",
    "\n",
    "second_term = (1 - p_y) * (1/(number_neigh_selected_barycenters-1)) * sum_ptk_norm\n",
    "print(second_term.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,) (500,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "847267.1001266912"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(first_term.shape, second_term.shape)\n",
    "\n",
    "d_r_S_Ss = np.sum(first_term + second_term)\n",
    "d_r_S_Ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triangle Collision Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lc_le_lo(p_t, m_c_e_o, Fs):\n",
    "    \"\"\"\n",
    "    Compute the collision loss term L_c.\n",
    "\n",
    "    Parameters:\n",
    "    - p_t: 1D numpy array containing the probabilities of each triangle (indices)\n",
    "    - m_c_t: 2D numpy array containing the number of faces penetrated by each triangle\n",
    "    - Fs: 3D numpy array representing the vertices of triangles\n",
    "\n",
    "    Returns:\n",
    "    - L_c: Collision loss term\n",
    "    \"\"\"\n",
    "    assert len(p_t) == len(m_c_e_o), \"Input arrays must have the same length\"\n",
    "\n",
    "    penalty_per_triangle = p_t * m_c_e_o\n",
    "\n",
    "    # Sum the penalties for all selected triangles\n",
    "    total_penalty = np.sum(penalty_per_triangle)\n",
    "\n",
    "    # Compute the collision loss term L_c\n",
    "    L_c_e_o = (1 / len(Fs)) * total_penalty\n",
    "\n",
    "    return L_c_e_o\n",
    "\n",
    "# Example usage:\n",
    "# Replace the arrays below with your actual data\n",
    "# p_t = selected_triangles_indexes\n",
    "# m_c_t = numpy array containing the number of faces penetrated by each triangle\n",
    "# Fs = 3D numpy array representing the vertices of triangles\n",
    "p_t = selected_triangles_indexes\n",
    "Fs = triangles  # Given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_neigh_barycenters = min(50, len(b_hat))\n",
    "_, indexes_neigh_selected_barycenters = NearestNeighbors(n_neighbors=number_neigh_barycenters).fit(b_hat).kneighbors(b_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_c :  2816.994580623645\n"
     ]
    }
   ],
   "source": [
    "mc = np.zeros((500))\n",
    "\n",
    "for index_neigh_barycenters in indexes_neigh_selected_barycenters:\n",
    "    current_triangle = selected_triangles[index_neigh_barycenters[0]]\n",
    "    others_triangles = selected_triangles[index_neigh_barycenters[1:]]\n",
    "\n",
    "    lines_current_triangle = LinearRing(current_triangle)\n",
    "    polygons_others_tri = MultiPolygon([Polygon(others_triangle) for others_triangle in others_triangles]).buffer(0)    # buffer 0 to correct invalid polygons => take the exterior of the shape\n",
    "\n",
    "\n",
    "    intersection = lines_current_triangle.intersection(polygons_others_tri)\n",
    "    if intersection.is_empty:\n",
    "        continue\n",
    "    if intersection.geom_type == 'MultiLineString':\n",
    "        mc[index_neigh_barycenters[0]] = len(intersection.geoms)\n",
    "    else:\n",
    "        mc[index_neigh_barycenters[0]] += 1\n",
    "L_c = compute_lc_le_lo(p_t, mc, Fs)\n",
    "print(\"L_c : \", L_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_e :  23092.200100050024\n"
     ]
    }
   ],
   "source": [
    "me = np.zeros((500))\n",
    "\n",
    "for index_neigh_barycenters in indexes_neigh_selected_barycenters:\n",
    "    current_triangle = selected_triangles[index_neigh_barycenters[0]]\n",
    "    others_triangles = selected_triangles[index_neigh_barycenters[1:]]\n",
    "\n",
    "    lines_current_triangle = LinearRing(current_triangle)\n",
    "    lines_others_tri = MultiLineString([LineString([other_tri[0], other_tri[1], other_tri[2], other_tri[0]]) for other_tri in others_triangles])\n",
    "\n",
    "    intersection = lines_current_triangle.intersection(lines_others_tri)\n",
    "    if intersection.is_empty:\n",
    "        continue\n",
    "    if intersection.geom_type == 'MultiLineString':\n",
    "        me[index_neigh_barycenters[0]] = len(intersection.geoms)\n",
    "    else:\n",
    "        me[index_neigh_barycenters[0]] += 1\n",
    "L_e = compute_lc_le_lo(p_t, me, Fs)\n",
    "print(\"L_e : \", L_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = np.zeros((500))\n",
    "L_o = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188905884.0018895\n"
     ]
    }
   ],
   "source": [
    "lambda_c, lambda_e, lambda_o = 0.01, 0.01, 0.01\n",
    "\n",
    "\n",
    "Loss_L = prob_chamfer_dist + d_f_S_Ss + d_r_S_Ss + (lambda_c * L_c) + (lambda_e * L_e) + (lambda_o * L_o)\n",
    "print(Loss_L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo - échantillonnage de 100 points à partir de chaque triangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_points_from_triangle(t, num_points=100):\n",
    "    v1, v2, v3 = t\n",
    "    bary_coords = np.random.rand(num_points, 2)\n",
    "    sqrt_bary_coords = np.sqrt(bary_coords[:, 0])\n",
    "\n",
    "    u = sqrt_bary_coords\n",
    "    v = bary_coords[:, 1]\n",
    "\n",
    "    \"\"\"\n",
    "    La formule spécifique est dérivée de l'expression générale d'interpolation barycentrique \n",
    "    sommets A, B et C\n",
    "    coord barycentriques: u et v\n",
    "    coord cartésiennes: x,y,z \n",
    "    \"\"\"\n",
    "    x_coords = (1 - u - v) * v1[0] + u * v2[0] + v * v3[0]\n",
    "    y_coords = (1 - u - v) * v1[1] + u * v2[1] + v * v3[1]\n",
    "    z_coords = (1 - u - v) * v1[2] + u * v2[2] + v * v3[2]\n",
    "\n",
    "    sampled_points = np.column_stack((x_coords, y_coords, z_coords))\n",
    "    return sampled_points\n",
    "\n",
    "points100 = sample_points_from_triangle(triangle, num_points=100)\n",
    "points100\n",
    "points100.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les Aires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_neigh_selected_barycenters = min(50, len(b_hat))\n",
    "def knnbar(nn):\n",
    "  _, indexes_neigh_selected_barycenters = NearestNeighbors(n_neighbors=nn).fit(b_hat).kneighbors(b_hat)\n",
    "  return _, indexes_neigh_selected_barycenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, indices = knnbar(number_neigh_selected_barycenters)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance as scipy_distance\n",
    "\n",
    "def calculate_triangle_area(triangle):\n",
    "    # Fonction pour calculer l'aire d'un triangle en utilisant la formule de Héron\n",
    "    side_lengths = [scipy_distance.euclidean(triangle[i], triangle[(i + 1) % 3]) for i in range(3)]\n",
    "    s = sum(side_lengths) / 2\n",
    "    return np.sqrt(s * np.prod([s - length for length in side_lengths]))\n",
    "\n",
    "def penalize_overlapping_triangles(points_list, triangles, k=50):\n",
    "    # Fonction pour pénaliser les triangles qui se chevauchent\n",
    "    assignment_results = []\n",
    "    overlapping_triangles = np.zeros(len(triangles), dtype=int)  # Déclaration en dehors de la boucle\n",
    "\n",
    "    # ajustement de la valeur maximale de k en fonction du nombre de triangles\n",
    "    k = min(k, len(triangles))\n",
    "\n",
    "    # NearestNeighbors pour trouver les k triangles les plus proches pour chaque point\n",
    "    knn_model = NearestNeighbors(n_neighbors=k).fit(np.vstack(triangles))\n",
    "    d, indices = knn_model.kneighbors(np.array(points_list)[:, 0, :])\n",
    "\n",
    "    for i, point_list in enumerate(points_list):\n",
    "        point = point_list[0]\n",
    "\n",
    "        # Verif que les indices sont valides\n",
    "        closest_triangle_indices = indices[i, :k]\n",
    "        closest_triangle_indices = closest_triangle_indices[closest_triangle_indices < len(triangles)]\n",
    "\n",
    "        # Accéder aux triangles en utilisant les indices valides\n",
    "        valid_triangle_indices = []\n",
    "        for idx in closest_triangle_indices:\n",
    "            modified_triangle = np.copy(triangles[idx])\n",
    "            modified_triangle[0] = point\n",
    "\n",
    "            area_original = calculate_triangle_area(triangles[idx])\n",
    "            area_modified = calculate_triangle_area(modified_triangle)\n",
    "\n",
    "            # Vérifier si la somme des aires est proche de l'aire du triangle\n",
    "            if not np.isclose(area_original, area_modified, rtol=1e-5):\n",
    "                assignment_results.append((point, triangles[idx]))\n",
    "                valid_triangle_indices.append(idx)\n",
    "\n",
    "        # MAJ du overlapping_triangles avec les indices valides\n",
    "        overlapping_triangles[valid_triangle_indices] += 1\n",
    "\n",
    "    penalties = overlapping_triangles\n",
    "    total_penalty = np.sum(penalties)\n",
    "    Lo = (1 / len(triangles)) * total_penalty\n",
    "\n",
    "    return Lo\n",
    "\n",
    "\n",
    "L_o = penalize_overlapping_triangles([points100], triangles, k=50)\n",
    "print(\"Pénalité pour les triangles qui se chevauchent :\", L_o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meshPFE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
