{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Transformation import Transformation\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import networkx as nx\n",
    "import torch\n",
    "from numpy import mean\n",
    "from igraph import Graph as igraphGraph\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import scipy.spatial.distance\n",
    "from scipy.spatial.distance import cdist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 5999\n",
      "Number of edges: 17991\n"
     ]
    }
   ],
   "source": [
    "transformation = Transformation()\n",
    "\n",
    "user_number_triangles = 500   #Ã  diminuer si le process est trop long\n",
    "number_neigh_tri = 20\n",
    "\n",
    "# Create objects\n",
    "stl_file_path = \"3d_models/stl/Handle.stl\"\n",
    "mesh_data = transformation.stl_to_mesh(stl_file_path)\n",
    "graph = transformation.mesh_to_graph(mesh_data)\n",
    "\n",
    "transformation.print_graph_properties(graph, display_graph=False, display_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(graph._node)<20:\n",
    "    raise Exception(\"Input mesh does not have enough vertices. (More than 20 is needed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DevConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(array):\n",
    "    return np.maximum(array, 0)\n",
    "\n",
    "def sigmoid(array):\n",
    "    return 1 / (1 + np.exp(-array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DevConv():\n",
    "    def __init__(self, graph, output_dimension):\n",
    "        self.graph = graph\n",
    "        self.list_node = list(graph._node)\n",
    "\n",
    "        self.W_phi = np.random.random((output_dimension))      #change\n",
    "        self.W_theta = np.array([0.1, 0.1, 0.1]).reshape(1, -1)  # change\n",
    "    \n",
    "    def forward(self, previous_inclusion_score, return_flatten=True):\n",
    "        list_inc_score = np.zeros((len(self.list_node), len(self.W_phi)))                               #list of \"output_dimension\" for each \"list_node\" element\n",
    "        for index_current_node, (current_node, dict_neigh) in enumerate(self.graph._adj.items()):       # for each node and its adjacency nodes\n",
    "            neigh_nodes = np.array(list(dict_neigh.keys()))                                             # array of adjacency nodes\n",
    "            diff = current_node - neigh_nodes                                                           # Compute the differences between current_node and all neighbor nodes   (x_i - x_j)\n",
    "            neigh_distances = np.linalg.norm(self.W_theta * diff, axis=1)                               # Compute the norm for each vector difference  ||W_theta * (x_i - x_j)||\n",
    "            list_inc_score[index_current_node] = self.W_phi * np.max(neigh_distances)                   # Add (W_phi * ||W_theta * (x_i - x_j)||) to the inclusion score list\n",
    "\n",
    "        if len(previous_inclusion_score)==0:                            # return if no previous inclusion score\n",
    "            if return_flatten:\n",
    "                list_inc_score = list_inc_score.flatten()\n",
    "            return list_inc_score\n",
    "        \n",
    "        if list_inc_score.shape[1]!=1:                                  # If inclusion score is not vector\n",
    "            list_inc_score = np.mean(list_inc_score, axis=1)            # Mean the matrix for each node\n",
    "\n",
    "        # array of array to array\n",
    "        if len(list_inc_score.shape)==2:                 \n",
    "            if list_inc_score.shape[1]==1:\n",
    "                list_inc_score = list_inc_score.flatten()\n",
    "\n",
    "        # Return the mean of previous and current inclusion score\n",
    "        return np.mean(np.array([previous_inclusion_score, list_inc_score], dtype=np.float64), axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76419333 0.76463794 0.76419333 ... 0.71143825 1.0327106  0.71143825]\n",
      "[0.72680424 0.7272271  0.72680424 ... 0.67663027 0.98218397 0.67663027]\n",
      "[0.72656961 0.72668255 0.72656961 ... 0.71296363 0.78929482 0.71296363]\n",
      "(5999,)\n"
     ]
    }
   ],
   "source": [
    "devconv = DevConv(graph, 1)\n",
    "inclusion_score = devconv.forward(previous_inclusion_score=np.array([]))\n",
    "inclusion_score = relu(inclusion_score)\n",
    "print(inclusion_score)\n",
    "\n",
    "devconv = DevConv(graph, 64)\n",
    "inclusion_score = devconv.forward(previous_inclusion_score=inclusion_score)\n",
    "inclusion_score = relu(inclusion_score)\n",
    "print(inclusion_score)\n",
    "\n",
    "devconv = DevConv(graph, 1)\n",
    "inclusion_score = devconv.forward(previous_inclusion_score=inclusion_score)\n",
    "inclusion_score = sigmoid(inclusion_score)\n",
    "print(inclusion_score)\n",
    "print(inclusion_score.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "normalized_inclusion_score = inclusion_score / np.sum(inclusion_score)  # normalize for multinomial sampling\n",
    "normalized_inclusion_score = np.round(normalized_inclusion_score, 8)    # round to remove float imprecision\n",
    "\n",
    "number_throws = 500     # small:more randomness    |   big:less randomness\n",
    "mult_sampling = np.random.multinomial(number_throws, normalized_inclusion_score)\n",
    "print(mult_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[89.04638  ,  4.7321377, 89.30968  ],\n",
       "       [88.121735 ,  4.7321377, 90.7335   ],\n",
       "       [87.05333  ,  4.7321377, 92.05287  ],\n",
       "       [87.604805 ,  4.7321377, 91.40717  ],\n",
       "       [83.627205 ,  5.2797017, 94.484726 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_number_point = min(len(graph._node), user_number_triangles*3)   # number of points for the simplification\n",
    "\n",
    "index_k_nodes = np.argpartition(mult_sampling, -target_number_point)[-target_number_point:]     # Take the k (\"target_number_points\") largest values given by the multinomial sampling \n",
    "list_k_nodes = np.array(graph)[index_k_nodes]                                # Take the selected nodes (list of list of 3)\n",
    "list_k_nodes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN extended graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n_, indices = NearestNeighbors(n_neighbors=15).fit(list_k_nodes).kneighbors(list_k_nodes)        # KNN of the selected points\\n\\nextended_graph = nx.Graph()\\nfor index_poly, poly in enumerate(indices):                                 # For the neighbors of the 'index_poly' node\\n    current_node = tuple(list_k_nodes[poly[0]])                             # Tuple of the main node coordinates\\n    for index_other_node in poly[1:]:                                       # For every neighbors of the main node (main node is the first index)\\n        edge = current_node, tuple(list_k_nodes[index_other_node])          # Create an edge of two tuples\\n        extended_graph.add_edge(*edge)                                      # Add the edge to the graph\\n\\ntransformation.print_graph_properties(graph=extended_graph, display_graph=False, display_labels=False)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "_, indices = NearestNeighbors(n_neighbors=15).fit(list_k_nodes).kneighbors(list_k_nodes)        # KNN of the selected points\n",
    "\n",
    "extended_graph = nx.Graph()\n",
    "for index_poly, poly in enumerate(indices):                                 # For the neighbors of the 'index_poly' node\n",
    "    current_node = tuple(list_k_nodes[poly[0]])                             # Tuple of the main node coordinates\n",
    "    for index_other_node in poly[1:]:                                       # For every neighbors of the main node (main node is the first index)\n",
    "        edge = current_node, tuple(list_k_nodes[index_other_node])          # Create an edge of two tuples\n",
    "        extended_graph.add_edge(*edge)                                      # Add the edge to the graph\n",
    "\n",
    "transformation.print_graph_properties(graph=extended_graph, display_graph=False, display_labels=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 1500\n",
      "Number of edges: 11807\n"
     ]
    }
   ],
   "source": [
    "def knn_and_extended_graph(list_k_nodes_i, k_neighbors=15):\n",
    "    \"\"\"\n",
    "    Perform k-NN on the given points and construct an extended graph.\n",
    "\n",
    "    Parameters:\n",
    "    - list_k_nodes_i: array-like\n",
    "        List of coordinates of the selected points.\n",
    "    - k_neighbors: int, optional (default=15)\n",
    "        Number of neighbors for k-NN.\n",
    "\n",
    "    Returns:\n",
    "    - extended_graph_i: networkx.Graph\n",
    "        Extended graph.\n",
    "    \"\"\"\n",
    "\n",
    "    # Perform k-NN on the selected points\n",
    "    _, indices = NearestNeighbors(n_neighbors=k_neighbors).fit(list_k_nodes_i).kneighbors(list_k_nodes_i)\n",
    "\n",
    "    # Construct the extended graph\n",
    "    extended_graph_i = nx.Graph()\n",
    "    for poly in indices:\n",
    "        current_node = tuple(list_k_nodes_i[poly[0]])\n",
    "        for index_other_node in poly[1:]:\n",
    "            edge = current_node, tuple(list_k_nodes_i[index_other_node])\n",
    "            extended_graph_i.add_edge(*edge)\n",
    "\n",
    "    return extended_graph_i\n",
    "\n",
    "extended_graph = knn_and_extended_graph(list_k_nodes)\n",
    "transformation.print_graph_properties(graph=extended_graph, display_graph=False, display_labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devconv = DevConv(extended_graph, 64)\n",
    "inclusion_score = devconv.forward(previous_inclusion_score=np.array([]), return_flatten=False)\n",
    "inclusion_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "inclusion_score = [[f_1_1  , f_1_2  , ..., f_63_1  ],\n",
    "                    ...,\n",
    "                   [f_1_M-1, f_1_M-1, ..., f_63_M-1]]\n",
    "M = number of points\n",
    "64 = hidden dimensions\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "f = np.mean(inclusion_score, axis=1)                            # Flatten the matrix of inclusion score \n",
    "wq = np.random.rand(64)\n",
    "wk = np.random.rand(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wq_f = wq.reshape(-1, 1) * f            # Wq*f\n",
    "wk_f = wk.reshape(-1, 1) * f            # Wq*f\n",
    "S = np.exp(np.dot(wq_f.T, wk_f))        # e^((wq_f.T)*(wk_f))\n",
    "\n",
    "nodes = list(extended_graph.nodes())                                                                                # list of nodes\n",
    "node_indices = {node: index for index, node in enumerate(nodes)}                                                    # dict{node: index}\n",
    "neighbors_indices = [[node_indices[neighbor] for neighbor in extended_graph.neighbors(node)] for node in nodes]     # List of list : [[neigh1 of node1, neigh2 of node1...], [neigh1 of node2, neigh2 of node2...]...]\n",
    "\n",
    "\n",
    "for index_current_node, neighbors_index in enumerate(neighbors_indices):        # For each neighbors of the 'index_current_node' node\n",
    "    sum_columns = np.sum(S[:, neighbors_index], axis=1)                         # Sum along the rows the values of the neighbors\n",
    "    S[index_current_node] = S[index_current_node] / sum_columns                 # And divide the current node columns by the sume of the neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S = S*np.random.choice([0, 1], size=S.shape)      # Add a random mask to emulate the 'sparse'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 14)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 13)\t1\n",
      "  (1, 14)\t1\n",
      "  :\t:\n",
      "  (1498, 1446)\t1\n",
      "  (1498, 1467)\t1\n",
      "  (1498, 1468)\t1\n",
      "  (1498, 1469)\t1\n",
      "  (1498, 1470)\t1\n",
      "  (1498, 1471)\t1\n",
      "  (1498, 1495)\t1\n",
      "  (1498, 1496)\t1\n",
      "  (1498, 1497)\t1\n",
      "  (1498, 1499)\t1\n",
      "  (1499, 1411)\t1\n",
      "  (1499, 1433)\t1\n",
      "  (1499, 1441)\t1\n",
      "  (1499, 1446)\t1\n",
      "  (1499, 1447)\t1\n",
      "  (1499, 1448)\t1\n",
      "  (1499, 1468)\t1\n",
      "  (1499, 1469)\t1\n",
      "  (1499, 1470)\t1\n",
      "  (1499, 1471)\t1\n",
      "  (1499, 1472)\t1\n",
      "  (1499, 1494)\t1\n",
      "  (1499, 1495)\t1\n",
      "  (1499, 1497)\t1\n",
      "  (1499, 1498)\t1\n",
      "[[0.07074653 0.07074291 0.07057048 ... 0.06997408 0.06999629 0.06997408]\n",
      " [1.14298693 0.07093672 0.07081278 ... 0.07038329 0.07039931 0.07038329]\n",
      " [1.10145439 0.54700737 0.06735767 ... 0.06773871 0.06772602 0.06773871]\n",
      " ...\n",
      " [1.2342367  1.22916099 1.36592742 ... 0.06751291 0.06751882 0.06751291]\n",
      " [1.1517689  1.14723458 1.27483239 ... 0.28331518 0.06387253 0.06387484]\n",
      " [1.23240879 1.227855   1.36713141 ... 0.56923194 0.4172229  0.07028187]]\n"
     ]
    }
   ],
   "source": [
    "adjacency = nx.adjacency_matrix(extended_graph)\n",
    "# S = np.random.rand(target_number_point, target_number_point)\n",
    "print(adjacency)\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_s = np.zeros((target_number_point,target_number_point))   # Init A_s to 0\n",
    "A_s = np.matmul(np.matmul(S, adjacency.toarray()), S.T)     # A_s = S * A * S.T\n",
    "A_s = A_s/A_s.max()                                         # Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.63017665e-30 4.70811019e-30 4.53179123e-30 ... 8.20846974e-29\n",
      "  8.45910320e-29 2.59123091e-28]\n",
      " [4.70811019e-30 4.78694793e-30 4.62836894e-30 ... 8.35398433e-29\n",
      "  8.60631094e-29 2.65423983e-28]\n",
      " [4.53179123e-30 4.62836894e-30 4.47581103e-30 ... 8.04840968e-29\n",
      "  8.29773180e-29 2.58304900e-28]\n",
      " ...\n",
      " [8.20846974e-29 8.35398433e-29 8.04840968e-29 ... 3.13745226e-27\n",
      "  3.00809060e-27 5.91266368e-27]\n",
      " [8.45910320e-29 8.60631094e-29 8.29773180e-29 ... 3.00809060e-27\n",
      "  2.91740316e-27 6.61199754e-27]\n",
      " [2.59123091e-28 2.65423983e-28 2.58304900e-28 ... 5.91266368e-27\n",
      "  6.61199754e-27 6.68894608e-26]]\n",
      "(1500, 1500)\n"
     ]
    }
   ],
   "source": [
    "print(A_s)  # symmÃ©trique\n",
    "print(A_s.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TriConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH U--- 1500 11807 -- \n",
      "+ attr: _nx_name (v)\n"
     ]
    }
   ],
   "source": [
    "igraph_g = igraphGraph(directed=extended_graph.is_directed()).from_networkx(extended_graph)\n",
    "print(igraph_g.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[903 905 910]\n",
      " [706 905 910]\n",
      " [705 706 910]]\n",
      "32524\n"
     ]
    }
   ],
   "source": [
    "triangles_ids_igraph = np.array(igraph_g.cliques(min=3, max=3))\n",
    "print(triangles_ids_igraph[:3])\n",
    "print(len(triangles_ids_igraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[78.294556  -7.328478  83.33951  ]\n",
      "  [77.74096   -6.9390492 83.19142  ]\n",
      "  [76.699425  -6.0434117 82.89942  ]]\n",
      "\n",
      " [[76.39445   -5.0095077 81.91051  ]\n",
      "  [77.74096   -6.9390492 83.19142  ]\n",
      "  [76.699425  -6.0434117 82.89942  ]]\n",
      "\n",
      " [[75.63655   -5.0095077 82.62972  ]\n",
      "  [76.39445   -5.0095077 81.91051  ]\n",
      "  [76.699425  -6.0434117 82.89942  ]]]\n",
      "32524\n"
     ]
    }
   ],
   "source": [
    "triangles = np.array(igraph_g.vs['_nx_name'])[triangles_ids_igraph]   #les triangles\n",
    "# triangles = [list(map(tuple, row)) for row in triangles.tolist()]\n",
    "print(triangles[:3])\n",
    "print(len(triangles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32524,)\n",
      "[1.45071848e-26 1.65933740e-24 1.80662278e-24 ... 3.45038925e-22\n",
      " 1.24997360e-18 3.44346422e-22]\n"
     ]
    }
   ],
   "source": [
    "# Extract indices for each triangle\n",
    "i, j, k = triangles_ids_igraph.T\n",
    "\n",
    "# Extract probabilities using advanced indexing\n",
    "A_s_ij = A_s[i, j]\n",
    "A_s_ik = A_s[i, k]\n",
    "A_s_jk = A_s[j, k]\n",
    "\n",
    "# Calculate the barycenter probabilities\n",
    "p_init = np.zeros(len(triangles))\n",
    "p_init = (A_s_ij + A_s_ik + A_s_jk) / 3\n",
    "\n",
    "print(p_init.shape)\n",
    "print(p_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate barycenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32524, 3)\n",
      "[[77.578316  -6.770313  83.143456 ]\n",
      " [76.94495   -5.9973226 82.667114 ]\n",
      " [76.24348   -5.3541427 82.47988  ]]\n"
     ]
    }
   ],
   "source": [
    "barycenters = np.mean(triangles, axis=1)\n",
    "print(barycenters.shape)\n",
    "print(barycenters[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Tri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, indices_neigh_tri = NearestNeighbors(n_neighbors=number_neigh_tri).fit(barycenters).kneighbors(barycenters)          # Find k='number_neigh_tri' neighbors of each triangles based on theirs barycenters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diff Barycenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32524, 19, 3)\n"
     ]
    }
   ],
   "source": [
    "# Calculates the difference between each barycenters and their n='number_neigh_tri'-1 neighbors\n",
    "barycenters_diff = np.subtract(barycenters[indices_neigh_tri[:, 0]][:, np.newaxis], barycenters[indices_neigh_tri[:, 1:]])   #Inverser la diffÃ©rence des barycentres si nÃ©cÃ©ssaire\n",
    "\n",
    "print(barycenters_diff.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate e norm matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32524, 3)\n",
      "[[0.6928588 2.0951166 1.4043591]\n",
      " [2.678986  1.4628468 1.4043591]]\n"
     ]
    }
   ],
   "source": [
    "diff_vectors = list()\n",
    "\n",
    "for triangle in triangles:\n",
    "    e_ij = np.linalg.norm(np.array(triangle[0]) - np.array(triangle[1]))    #Calculate the vectors for each edge of each triangles\n",
    "    e_ik = np.linalg.norm(np.array(triangle[0]) - np.array(triangle[2]))\n",
    "    e_jk = np.linalg.norm(np.array(triangle[1]) - np.array(triangle[2]))\n",
    "    diff_vectors.append([e_ij, e_ik, e_jk])\n",
    "\n",
    "diff_vectors = np.array(diff_vectors)\n",
    "print(diff_vectors.shape)\n",
    "print(diff_vectors[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32524,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_diff_vectors = diff_vectors.max(axis=1)       # calculate t_n_max\n",
    "min_diff_vectors = diff_vectors.min(axis=1)       # calculate t_n_min\n",
    "max_diff_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32524, 19)\n",
      "(32524, 19)\n"
     ]
    }
   ],
   "source": [
    "max_diff_vectors_diff = np.subtract(max_diff_vectors[indices_neigh_tri[:, 0]][:, np.newaxis], max_diff_vectors[indices_neigh_tri[:, 1:]])   #Inverser la diffÃ©rence des barycentres si nÃ©cÃ©ssaire   # calculate t_n_max - t_m_max\n",
    "print(max_diff_vectors_diff.shape)\n",
    "min_diff_vectors_diff = np.subtract(min_diff_vectors[indices_neigh_tri[:, 0]][:, np.newaxis], min_diff_vectors[indices_neigh_tri[:, 1:]])   #Inverser la diffÃ©rence des barycentres si nÃ©cÃ©ssaire   # calculate t_n_min - t_m_min\n",
    "print(min_diff_vectors_diff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32524, 19, 5)\n"
     ]
    }
   ],
   "source": [
    "r_matrix = np.zeros((len(triangles), number_neigh_tri-1, 5))\n",
    "\n",
    "r_matrix[:, :, 0]   = min_diff_vectors_diff\n",
    "r_matrix[:, :, 1]   = max_diff_vectors_diff\n",
    "r_matrix[:, :, 2:5] = barycenters_diff\n",
    "\n",
    "print(r_matrix.shape)  # nb_triangles, len(indices_neigh_tri), 5dim/triangles\n",
    "\n",
    "# Here r_matrix[i,j] represent the relation between the triangles (n = i) and (m = indices_neigh_tri_array[i,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999998828\n",
      "(32524,)\n",
      "[3.07406003e-05 3.07406003e-05 3.07406003e-05 ... 3.07406003e-05\n",
      " 3.07406003e-05 3.07406003e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahdel\\AppData\\Local\\Temp\\ipykernel_1496\\474768578.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  final_scores = torch.nn.functional.softmax(torch.tensor(f_final))    #proba des triangles\n"
     ]
    }
   ],
   "source": [
    "# Multi Layer Perceptron (MLP) * 3 \n",
    "f_final = p_init    # TODO\n",
    "\n",
    "\n",
    "final_scores = torch.nn.functional.softmax(torch.tensor(f_final))    #proba des triangles\n",
    "final_scores = final_scores.numpy()\n",
    "print(final_scores.sum())\n",
    "print(final_scores.shape)\n",
    "print(final_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 3, 3)\n",
      "[[39.        -7.9077644 93.86099  ]\n",
      " [51.         7.0402236 84.7203   ]\n",
      " [63.        -8.57404   88.01863  ]]\n"
     ]
    }
   ],
   "source": [
    "selected_triangles_indexes = np.argpartition(final_scores, -int(target_number_point/3))[-int(target_number_point/3):] \n",
    "selected_triangles = np.array(triangles)[selected_triangles_indexes]\n",
    "print(selected_triangles.shape) # number triangles, number points, number dimensions(x,y,z)\n",
    "print(selected_triangles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 45\n",
      "Number of edges: 224\n"
     ]
    }
   ],
   "source": [
    "simplified_final_graph = nx.Graph()\n",
    "for index_poly, poly in enumerate(selected_triangles):\n",
    "    for index_current_node in range(len(poly)):\n",
    "        current_node = tuple(poly[index_current_node])\n",
    "        for index_other_node in range(index_current_node+1, len(poly)):\n",
    "            edge = current_node, tuple(poly[index_other_node])\n",
    "            simplified_final_graph.add_edge(*edge)\n",
    "            # if attribute do not exists\n",
    "            if len(simplified_final_graph.nodes[current_node])==0:\n",
    "                simplified_final_graph.nodes[current_node]['index_triangle'] = set()\n",
    "            simplified_final_graph.nodes[current_node]['index_triangle'].add(index_poly)\n",
    "            if len(simplified_final_graph.nodes[tuple(poly[index_other_node])])==0:\n",
    "                simplified_final_graph.nodes[tuple(poly[index_other_node])]['index_triangle'] = set()\n",
    "            simplified_final_graph.nodes[tuple(poly[index_other_node])]['index_triangle'].add(index_poly)\n",
    "            \n",
    "transformation.print_graph_properties(graph=simplified_final_graph, display_graph=False, display_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_final_mesh = transformation.graph_to_mesh(simplified_final_graph)\n",
    "\n",
    "#Affichage\n",
    "transformation.mesh_to_display_vtk(mesh_data)\n",
    "transformation.mesh_to_display_vtk(simplified_final_mesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Chamfer distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RÃ©cupÃ©ration des points de l'espace de dÃ©part P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les points avant K-NN :  [[75.0252     -0.66553295  3.8       ]\n",
      " [75.01418    -0.49935842 16.7       ]\n",
      " [75.          0.          3.8       ]\n",
      " ...\n",
      " [51.         -8.57404    -6.9813724 ]\n",
      " [39.         -8.699333   -6.327254  ]\n",
      " [51.         -8.699333   -6.327254  ]]\n",
      "dim points avant K-NN :  5999\n"
     ]
    }
   ],
   "source": [
    "keys_input = np.array(graph)\n",
    "print(\"Les points avant K-NN : \", keys_input)\n",
    "print(\"dim points avant K-NN : \", len(keys_input))  #return 5999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RÃ©cupÃ©ration des points de l'espace de dÃ©part Ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled points :  [[89.04638    4.7321377 89.30968  ]\n",
      " [89.33791    4.1574683 89.478    ]\n",
      " [88.71803    5.2797017 89.12011  ]\n",
      " ...\n",
      " [86.70247   -7.8332825 86.41028  ]\n",
      " [86.41375   -7.8332825 87.015594 ]\n",
      " [86.09374   -7.8332825 87.60497  ]]\n",
      "dim sample points :  1500\n"
     ]
    }
   ],
   "source": [
    "keys_output = np.array(extended_graph)\n",
    "print(\"sampled points : \", keys_output)\n",
    "print(\"dim sample points : \", len(keys_output))  #return: 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squared Euclidean Distances Matrix Shape: (1500, 5999)\n",
      "Distances Matrix:\n",
      " [[ 7537.63320434  5496.4361785   7531.59878255 ... 10896.5475473\n",
      "  11831.46702982 10774.35393168]\n",
      " [ 7568.83426078  5523.49200076  7563.57945505 ... 10936.29683024\n",
      "  11877.84893302 10813.7390087 ]\n",
      " [ 7502.36059237  5465.86519297  7495.5807782  ... 10850.07099805\n",
      "  11777.49538147 10728.26259339]\n",
      " ...\n",
      " [ 7012.19333615  5049.92526476  7022.76618401 ...  9997.21542201\n",
      "  10876.52544754  9875.66619461]\n",
      " [ 7105.91087289  5128.01928199  7116.46916936 ... 10090.11216468\n",
      "  10961.7010329   9967.77104023]\n",
      " [ 7197.16274648  5204.05814207  7207.70491465 ... 10178.6961734\n",
      "  11041.83381922 10055.58400233]]\n"
     ]
    }
   ],
   "source": [
    "def matrix_distance_euclidienne_barycentres(barycentre_b, barycentre_b_hat):\n",
    "    \"\"\"\n",
    "    Calculate distances between barycenters b et b_hat after the k-NN process.\n",
    "\n",
    "    Parameters:\n",
    "    - b_hat: array-like, shape (M, 3)\n",
    "        Barycenters after k-NN.\n",
    "    - number_neigh: int, optional (default=3)\n",
    "        Number of neighbors for k-NN.\n",
    "\n",
    "    Returns:\n",
    "    - distances_after: array-like, shape (M, M)\n",
    "        Matrix of distances between barycenters after the k-NN process.\n",
    "    \"\"\"\n",
    "    return cdist(barycentre_b, barycentre_b_hat, metric='sqeuclidean').T\n",
    "\n",
    "distances_matrix = matrix_distance_euclidienne_barycentres(keys_input, keys_output)\n",
    "print(\"Squared Euclidean Distances Matrix Shape:\", distances_matrix.shape)\n",
    "print(\"Distances Matrix:\\n\", distances_matrix)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le min des x de distances_matrix\n",
    "def min_pour_x_list(distances_matrix, x_in):\n",
    "    return np.min(distances_matrix[:, x_in])\n",
    "\n",
    "# Calculer le min des y de distances_matrix\n",
    "def min_pour_y_list(distances_matrix, y_out):\n",
    "    return np.min(distances_matrix[y_out, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_P_Ps(keys_x, keys_y, p_y):\n",
    "    \"\"\"\n",
    "    Calculate the Probabilistic Chamfer distance between two sets of points.\n",
    "\n",
    "    Parameters:\n",
    "    - keys_x (list): The input vertex set, a list of tuples.\n",
    "    - keys_y (list): The sampled points, a list of tuples.\n",
    "    - p_y (list): Their respective probabilities, a weight associated with each point in keys_y.\n",
    "\n",
    "    Returns:\n",
    "        chamfer_distance (float): The Probabilistic Chamfer distance between the two sets of points.\n",
    "    \"\"\"\n",
    "    min_for_x = [p_y[i] * min_pour_x_list(distances_matrix, i) for i in range(len(keys_x))]\n",
    "    min_for_y = [p_y[j] * min_pour_y_list(distances_matrix, j) for j in range(len(keys_y))]\n",
    "    \n",
    "    sum_for_y = np.sum(min_for_y)\n",
    "    sum_for_x = np.sum(min_for_x)\n",
    "\n",
    "    chamfer_distance = sum_for_y + sum_for_x\n",
    "    \n",
    "    return chamfer_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBA :  [0.00021659 0.00021663 0.00021659 ... 0.00021254 0.00023529 0.00021254]\n"
     ]
    }
   ],
   "source": [
    "print(\"PROBA : \", normalized_inclusion_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chamfer Distance: 5.014634247657209\n"
     ]
    }
   ],
   "source": [
    "prob_chamfer_dist = d_P_Ps(keys_input, keys_output, normalized_inclusion_score)\n",
    "print(\"Chamfer Distance:\", prob_chamfer_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Surfaces Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "barycentres b et b_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH U--- 5999 17991 -- \n",
      "+ attr: _nx_name (v), index_triangle (v)\n",
      "triangles shape :  (11994, 3, 3)\n",
      "[[39.        8.793697 -4.666995]\n",
      " [51.        8.793697 -4.666995]\n",
      " [39.        8.793697 -5.333005]]\n",
      "shape b :  (11994, 3)\n",
      "Barycentre b:  [[43.          8.793697   -4.8889985 ]\n",
      " [55.          1.0515273   3.7313068 ]\n",
      " [55.         -8.515905   -2.804371  ]\n",
      " ...\n",
      " [75.05613    -0.94137865 21.        ]\n",
      " [75.01313    -0.3882971   8.099999  ]\n",
      " [75.03516    -0.72036856 25.300001  ]]\n"
     ]
    }
   ],
   "source": [
    "# Creation igraph\n",
    "igraph_g_original = igraphGraph(directed=extended_graph.is_directed()).from_networkx(graph)\n",
    "print(igraph_g_original.summary())\n",
    "\n",
    "#Find triangles\n",
    "triangles_ids_igraph_original = np.array(igraph_g_original.cliques(min=3, max=3))\n",
    "triangles = np.array(igraph_g_original.vs['_nx_name'])[triangles_ids_igraph_original]\n",
    "print(\"triangles shape : \", triangles.shape)\n",
    "print(triangles[0])\n",
    "\n",
    "# Calculate barycenters\n",
    "b = np.mean(triangles, axis=1)\n",
    "print(\"shape b : \", b.shape)\n",
    "print(\"Barycentre b: \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 3)\n",
      "B_HAT :  [[ 51.         -3.147194   88.86664  ]\n",
      " [ 51.         -2.3899596  81.80843  ]\n",
      " [ 51.         -2.7398205  82.08131  ]\n",
      " ...\n",
      " [ 47.          4.1359315 -10.814036 ]\n",
      " [ 39.         -4.434086   -7.9858613]\n",
      " [ 43.         -3.6821384  -6.899863 ]]\n"
     ]
    }
   ],
   "source": [
    "# Get finals selected triangles & calculate barycenters\n",
    "b_hat = np.mean(selected_triangles, axis=1)\n",
    "print(b_hat.shape)\n",
    "print(\"B_HAT : \", b_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test matrice des normes euclidiennes entre b et b_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 11994)\n",
      "Distances euclidiennes entre les barycentres b et b_hat :\n",
      " [[8996.70429575 7281.65391074 8448.39700934 ... 5189.44356367\n",
      "  7107.49186888 4624.29556169]\n",
      " [7705.51890488 6123.88155183 7212.85392298 ... 4278.46133977\n",
      "  6013.57033224 3773.67920109]\n",
      " [7760.85597958 6169.0967654  7254.94141432 ... 4312.85775595\n",
      "  6055.39387341 3805.88355506]\n",
      " ...\n",
      " [  72.80085651  285.08055712  288.22371367 ... 1825.05838844\n",
      "  1162.94485751 2113.77734174]\n",
      " [ 200.56480763  423.38397928  299.50909123 ... 2152.42363024\n",
      "  1572.06886783 2420.27282077]\n",
      " [ 159.69005398  279.42935717  184.13835464 ... 1813.50954227\n",
      "  1260.685761   2071.85455264]]\n"
     ]
    }
   ],
   "source": [
    "distances = matrix_distance_euclidienne_barycentres(b, b_hat)\n",
    "print(distances.shape)\n",
    "print(\"Distances euclidiennes entre les barycentres b et b_hat :\\n\", distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "[45.69712659 16.11604068 16.17244063 16.5260575  16.96616842]\n"
     ]
    }
   ],
   "source": [
    "minimums_b = np.min(distances, axis=1)\n",
    "print(minimums_b.shape)\n",
    "print(minimums_b[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147748927.03996018\n"
     ]
    }
   ],
   "source": [
    "d_f_S_Ss = np.sum(selected_triangles_indexes * minimums_b)\n",
    "print(d_f_S_Ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matrice sqeuclidean b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11994,)\n",
      "[1950.2314 3040.0283 3105.3853 ... 6075.3086 5692.7305 6270.884 ]\n"
     ]
    }
   ],
   "source": [
    "def normes_euclidiennes_carrees_b(bar_b):\n",
    "    # Calculer la matrice des normes euclidiennes au carrÃ©\n",
    "    normes_carrees = np.sum(bar_b**2, axis=1)\n",
    "\n",
    "    return normes_carrees\n",
    "\n",
    "matrix_b = normes_euclidiennes_carrees_b(b)\n",
    "print(matrix_b.shape)\n",
    "print(matrix_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances After k-NN:\n",
      " [[ 0.          4.0750322   4.11605999 ... 94.85239976 93.48194688\n",
      "  92.41829745]\n",
      " [ 4.0750322   0.          0.22200313 ... 95.12330824 93.75941502\n",
      "  92.67036796]\n",
      " [ 4.11605999  0.22200313  0.         ... 95.34266996 93.97749569\n",
      "  92.89024164]\n",
      " ...\n",
      " [94.85239976 95.12330824 95.34266996 ...  0.          3.86468243\n",
      "   3.1547582 ]\n",
      " [93.48194688 93.75941502 93.97749569 ...  3.86468243  0.\n",
      "   5.6318603 ]\n",
      " [92.41829745 92.67036796 92.89024164 ...  3.1547582   5.6318603\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "def matrix_distances_after_knn(b_hat_n, number_neigh=3):\n",
    "    \"\"\"\n",
    "    Calculate distances between barycenters after the k-NN process.\n",
    "\n",
    "    Parameters:\n",
    "    - b_hat: array-like, shape (M, 3)\n",
    "        Barycenters after k-NN.\n",
    "    - number_neigh: int, optional (default=3)\n",
    "        Number of neighbors for k-NN.\n",
    "\n",
    "    Returns:\n",
    "    - distances_after: array-like, shape (M, M)\n",
    "        Matrix of distances between barycenters after the k-NN process.\n",
    "    \"\"\"\n",
    "\n",
    "    # Connect the extended graph using the k-NN process\n",
    "    extended_graph = knn_and_extended_graph(b_hat_n, number_neigh)\n",
    "\n",
    "    # Extract barycenters after the k-NN process\n",
    "    b_hat_extended = np.array(list(extended_graph._node.keys()))\n",
    "\n",
    "    # Calculate distances after k-NN\n",
    "    distances_after = cdist(b_hat_extended, b_hat_extended)\n",
    "\n",
    "    return distances_after\n",
    "\n",
    "# Example usage with b_hat\n",
    "distances_after = matrix_distances_after_knn(b_hat)\n",
    "\n",
    "# Print the results\n",
    "print(\"Distances After k-NN:\\n\", distances_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triangle Collision Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collision Loss: 196152.67066575598\n"
     ]
    }
   ],
   "source": [
    "def L_c(p_t, m_c_t, Fs):\n",
    "    \"\"\"\n",
    "    Compute the collision loss term L_c.\n",
    "\n",
    "    Parameters:\n",
    "    - p_t: 1D numpy array containing the probabilities of each triangle (indices)\n",
    "    - m_c_t: 2D numpy array containing the number of faces penetrated by each triangle\n",
    "    - Fs: 3D numpy array representing the vertices of triangles\n",
    "\n",
    "    Returns:\n",
    "    - L_c: Collision loss term\n",
    "    \"\"\"\n",
    "    assert len(p_t) == len(m_c_t), \"Input arrays must have the same length\"\n",
    "\n",
    "    penalty_per_triangle = p_t * m_c_t\n",
    "\n",
    "    # Sum the penalties for all selected triangles\n",
    "    total_penalty = np.sum(penalty_per_triangle)\n",
    "\n",
    "    # Compute the collision loss term L_c\n",
    "    L_c = (1 / len(Fs)) * total_penalty\n",
    "\n",
    "    return L_c\n",
    "\n",
    "# Example usage:\n",
    "# Replace the arrays below with your actual data\n",
    "# p_t = selected_triangles_indexes\n",
    "# m_c_t = numpy array containing the number of faces penetrated by each triangle\n",
    "# Fs = 3D numpy array representing the vertices of triangles\n",
    "p_t = selected_triangles_indexes\n",
    "m_c_t = np.random.rand(500, 1)  # Given data\n",
    "Fs = triangles  # Given data\n",
    "\n",
    "collision_loss = L_c(p_t, m_c_t, Fs)\n",
    "print(\"Collision Loss:\", collision_loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meshPFE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
