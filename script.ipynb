{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Transformation import Transformation\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import nn\n",
    "from numpy import mean\n",
    "#!pip install igraph\n",
    "from igraph import Graph as igraphGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 5999\n",
      "Number of edges: 17991\n"
     ]
    }
   ],
   "source": [
    "transformation = Transformation()\n",
    "\n",
    "user_number_triangles = 500\n",
    "number_neigh_tri = 20\n",
    "\n",
    "# Create objects\n",
    "stl_file_path = \"3d_models/stl/Handle.stl\"\n",
    "mesh_data = transformation.stl_to_mesh(stl_file_path)\n",
    "graph = transformation.mesh_to_graph(mesh_data)\n",
    "\n",
    "transformation.print_graph_properties(graph, display_graph=False, display_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(graph._node)<20:\n",
    "    raise Exception(\"Input mesh does not have enough vertices. (More than 20 is needed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DevConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(array):\n",
    "    return np.maximum(array, 0)\n",
    "\n",
    "def sigmoid(array):\n",
    "    return 1 / (1 + np.exp(-array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DevConv(nn.Module):\n",
    "    def __init__(self, graph, output_dimension):\n",
    "        super().__init__()\n",
    "        self.graph = graph\n",
    "        self.list_node = list(graph._node)\n",
    "\n",
    "        self.W_phi = torch.tensor(np.random.random((output_dimension))) #change #passer en tensor\n",
    "        self.W_theta = torch.tensor(np.array([0.1, 0.1, 0.1]).reshape(1, -1))  # change #passer en tensor\n",
    "        print(\"self.W_theta.shape : \" )\n",
    "        print(self.W_theta.shape)\n",
    "    \n",
    "    # objective plus de np dans le forward, que utiliser des fonction pytorch (nn.)\n",
    "    def forward(self, previous_inclusion_score, return_flatten=True):\n",
    "        list_inc_score = np.zeros((len(self.list_node), len(self.W_phi)))                               #list of \"output_dimension\" for each \"list_node\" element\n",
    "        for index_current_node, (current_node, dict_neigh) in enumerate(self.graph._adj.items()):       # for each node and its adjacency nodes\n",
    "            neigh_nodes = np.array(list(dict_neigh.keys()))                                             # array of adjacency nodes\n",
    "            diff = current_node - neigh_nodes                                                           # Compute the differences between current_node and all neighbor nodes   (x_i - x_j)\n",
    "            neigh_distances = np.linalg.norm(self.W_theta * diff, axis=1)                               # Compute the norm for each vector difference  ||W_theta * (x_i - x_j)||\n",
    "            list_inc_score[index_current_node] = self.W_phi * np.max(neigh_distances)                   # Add (W_phi * ||W_theta * (x_i - x_j)||) to the inclusion score list\n",
    "\n",
    "        if len(previous_inclusion_score)==0:                            # return if no previous inclusion score\n",
    "            if return_flatten:\n",
    "                list_inc_score = list_inc_score.flatten()\n",
    "            return list_inc_score\n",
    "        \n",
    "        if list_inc_score.shape[1]!=1:                                  # If inclusion score is not vector\n",
    "            list_inc_score = np.mean(list_inc_score, axis=1)            # Mean the matrix for each node\n",
    "\n",
    "        # array of array to array\n",
    "        if len(list_inc_score.shape)==2:                 \n",
    "            if list_inc_score.shape[1]==1:\n",
    "                list_inc_score = list_inc_score.flatten()\n",
    "\n",
    "        # Return the mean of previous and current inclusion score\n",
    "        print(\"previous_inclusion score : \")\n",
    "        print(previous_inclusion_score.shape)\n",
    "        \n",
    "        print(\"list_inc_score : \")\n",
    "        print(list_inc_score.shape)\n",
    "        result_np = torch.stack([previous_inclusion_score, torch.tensor(list_inc_score)])\n",
    "        print(\"result_np.shape : \")\n",
    "        print(result_np.shape)\n",
    "        \n",
    "        result_np = torch.mean(result_np, axis=0)\n",
    "        print(\"mean.shape : \")\n",
    "        print(result_np.shape)\n",
    "        \n",
    "        # result_np =  torch.from_numpy(result_np)\n",
    "        # print(\"devconv tensor shape : \")\n",
    "        # print(result_np.shape)\n",
    "        #return torch.from_numpy(np.mean(np.array([previous_inclusion_score, list_inc_score], dtype=np.float64), axis=0))\n",
    "        return result_np\n",
    "    \n",
    "    \n",
    "#Tensor.numpy() pour commencer, à la fin repasser en tensor normaux.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GNN_Model, self).__init__()\n",
    "        # self.linear = nn.Sequential(\n",
    "        #     DevConv(graph, 1),\n",
    "        #     nn.ReLU(),\n",
    "        #     DevConv(graph, 64),\n",
    "        #     nn.ReLU(),\n",
    "        #     DevConv(graph, 1),\n",
    "        #     nn.Sigmoid()\n",
    "        # )\n",
    "        self.devconv = DevConv(graph,1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.devconv2 = DevConv(graph, 64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.devconv3 = DevConv(graph,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x= self.devconv(x)\n",
    "        x= torch.tensor(x)\n",
    "        #print(x)\n",
    "        x= self.relu(x)\n",
    "        x= self.devconv2(x)\n",
    "        x= self.relu2(x)\n",
    "        x= self.devconv3(x)\n",
    "        x= self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.W_theta.shape : \n",
      "torch.Size([1, 3])\n",
      "self.W_theta.shape : \n",
      "torch.Size([1, 3])\n",
      "self.W_theta.shape : \n",
      "torch.Size([1, 3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous_inclusion score : \n",
      "torch.Size([5999])\n",
      "list_inc_score : \n",
      "(5999,)\n",
      "result_np.shape : \n",
      "torch.Size([2, 5999])\n",
      "mean.shape : \n",
      "torch.Size([5999])\n",
      "previous_inclusion score : \n",
      "torch.Size([5999])\n",
      "list_inc_score : \n",
      "(5999,)\n",
      "result_np.shape : \n",
      "torch.Size([2, 5999])\n",
      "mean.shape : \n",
      "torch.Size([5999])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)  #  for repeatable results\n",
    "gnn = GNN_Model()\n",
    "# inp = np.array([[[[1,2,3,4],  # batch(=1) x channels(=1) x height x width\n",
    "#                   [1,2,3,4],\n",
    "#                   [1,2,3,4]]]])\n",
    "inp = np.array([])\n",
    "x = torch.tensor(inp, dtype=torch.float)\n",
    "inclusion_score = gnn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[88.3909, -7.5076, 81.2000],\n",
      "        [87.6610, -7.9078, 29.6000],\n",
      "        [51.0000, -8.7748, -4.3345],\n",
      "        ...,\n",
      "        [51.0000, -8.1771, -8.2519],\n",
      "        [75.0000,  5.7970, 96.6208],\n",
      "        [75.0000,  4.1575, 97.7560]])\n"
     ]
    }
   ],
   "source": [
    "normalized_inclusion_score = inclusion_score / np.sum(inclusion_score)  # normalize for multinomial sampling\n",
    "normalized_inclusion_score = np.round(normalized_inclusion_score, 8)    # round to remove float imprecision\n",
    "\n",
    "number_throws = 500     # small:more randomness    |   big:less randomness\n",
    "mult_sampling = np.random.multinomial(number_throws, normalized_inclusion_score)\n",
    "print(mult_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[85.318504 ,  5.7970243, 92.65986  ],\n",
       "       [85.90413  ,  5.7970243, 92.104126 ],\n",
       "       [84.064095 ,  5.7970243, 93.67566  ],\n",
       "       [83.39875  ,  5.7970243, 94.13294  ],\n",
       "       [87.47566  ,  5.7970243, 90.2641   ]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_number_point = min(len(graph._node), user_number_triangles*3)   # number of points for the simplification\n",
    "\n",
    "index_k_nodes = np.argpartition(mult_sampling, -target_number_point)[-target_number_point:]     # Take the k (\"target_number_points\") largest values given by the multinomial sampling \n",
    "list_k_nodes = np.array(list(graph._node.keys()))[index_k_nodes]                                # Take the selected nodes (list of list of 3)\n",
    "list_k_nodes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN extended graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n_, indices = NearestNeighbors(n_neighbors=15).fit(list_k_nodes).kneighbors(list_k_nodes)        # KNN of the selected points\\n\\nextended_graph = nx.Graph()\\nfor index_poly, poly in enumerate(indices):                                 # For the neighbors of the 'index_poly' node\\n    current_node = tuple(list_k_nodes[poly[0]])                             # Tuple of the main node coordinates\\n    for index_other_node in poly[1:]:                                       # For every neighbors of the main node (main node is the first index)\\n        edge = current_node, tuple(list_k_nodes[index_other_node])          # Create an edge of two tuples\\n        extended_graph.add_edge(*edge)                                      # Add the edge to the graph\\n\\ntransformation.print_graph_properties(graph=extended_graph, display_graph=False, display_labels=False)\\n\""
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, indices = NearestNeighbors(n_neighbors=15).fit(list_k_nodes).kneighbors(list_k_nodes)        # KNN of the selected points\n",
    "\n",
    "extended_graph = nx.Graph()\n",
    "for index_poly, poly in enumerate(indices):                                 # For the neighbors of the 'index_poly' node\n",
    "    current_node = tuple(list_k_nodes[poly[0]])                             # Tuple of the main node coordinates\n",
    "    for index_other_node in poly[1:]:                                       # For every neighbors of the main node (main node is the first index)\n",
    "        edge = current_node, tuple(list_k_nodes[index_other_node])          # Create an edge of two tuples\n",
    "        extended_graph.add_edge(*edge)                                      # Add the edge to the graph\n",
    "\n",
    "transformation.print_graph_properties(graph=extended_graph, display_graph=False, display_labels=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 22500\n",
      "Number of edges: 21000\n"
     ]
    }
   ],
   "source": [
    "def knn_and_extended_graph(list_k_nodes_i, k_neighbors=15):\n",
    "    \"\"\"\n",
    "    Perform k-NN on the given points and construct an extended graph.\n",
    "\n",
    "    Parameters:\n",
    "    - list_k_nodes_i: array-like\n",
    "        List of coordinates of the selected points.\n",
    "    - k_neighbors: int, optional (default=15)\n",
    "        Number of neighbors for k-NN.\n",
    "\n",
    "    Returns:\n",
    "    - extended_graph_i: networkx.Graph\n",
    "        Extended graph.\n",
    "    \"\"\"\n",
    "\n",
    "    # Perform k-NN on the selected points\n",
    "    _, indices = NearestNeighbors(n_neighbors=k_neighbors).fit(list_k_nodes_i).kneighbors(list_k_nodes_i)\n",
    "\n",
    "    # Construct the extended graph\n",
    "    extended_graph_i = nx.Graph()\n",
    "    for poly in indices:\n",
    "        current_node = tuple(list_k_nodes_i[poly[0]])\n",
    "        for index_other_node in poly[1:]:\n",
    "            edge = current_node, tuple(list_k_nodes_i[index_other_node])\n",
    "            extended_graph_i.add_edge(*edge)\n",
    "\n",
    "    return extended_graph_i\n",
    "\n",
    "extended_graph = knn_and_extended_graph(list_k_nodes)\n",
    "transformation.print_graph_properties(graph=extended_graph, display_graph=False, display_labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.W_theta.shape : \n",
      "torch.Size([1, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22500, 64)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devconv = DevConv(extended_graph, 64)\n",
    "inclusion_score = devconv.forward(previous_inclusion_score=np.array([]), return_flatten=False)\n",
    "inclusion_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22500, 22500])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "inclusion_score = [[f_1_1  , f_1_2  , ..., f_63_1  ],\n",
    "                    ...,\n",
    "                   [f_1_M-1, f_1_M-1, ..., f_63_M-1]]\n",
    "M = number of points\n",
    "64 = hidden dimensions\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "f = np.mean(inclusion_score, axis=1)                            # Flatten the matrix of inclusion score \n",
    "wq = np.random.rand(64)\n",
    "wk = np.random.rand(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wq_f = wq.reshape(-1, 1) * f            # Wq*f\n",
    "wk_f = wk.reshape(-1, 1) * f            # Wq*f\n",
    "S = np.exp(np.dot(wq_f.T, wk_f))        # e^((wq_f.T)*(wk_f))\n",
    "\n",
    "nodes = list(extended_graph.nodes())                                                                                # list of nodes\n",
    "node_indices = {node: index for index, node in enumerate(nodes)}                                                    # dict{node: index}\n",
    "neighbors_indices = [[node_indices[neighbor] for neighbor in extended_graph.neighbors(node)] for node in nodes]     # List of list : [[neigh1 of node1, neigh2 of node1...], [neigh1 of node2, neigh2 of node2...]...]\n",
    "\n",
    "\n",
    "for index_current_node, neighbors_index in enumerate(neighbors_indices):        # For each neighbors of the 'index_current_node' node\n",
    "    sum_columns = np.sum(S[:, neighbors_index], axis=1)                         # Sum along the rows the values of the neighbors\n",
    "    S[index_current_node] = S[index_current_node] / sum_columns                 # And divide the current node columns by the sume of the neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S = S*np.random.choice([0, 1], size=S.shape)      # Add a random mask to emulate the 'sparse'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 15)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 0)\t1\n",
      "  (3, 0)\t1\n",
      "  (4, 0)\t1\n",
      "  (5, 0)\t1\n",
      "  (6, 0)\t1\n",
      "  (7, 0)\t1\n",
      "  (8, 0)\t1\n",
      "  (9, 0)\t1\n",
      "  (10, 0)\t1\n",
      "  (11, 0)\t1\n",
      "  :\t:\n",
      "  (22485, 22489)\t1\n",
      "  (22485, 22490)\t1\n",
      "  (22485, 22491)\t1\n",
      "  (22485, 22492)\t1\n",
      "  (22485, 22493)\t1\n",
      "  (22485, 22494)\t1\n",
      "  (22485, 22495)\t1\n",
      "  (22485, 22496)\t1\n",
      "  (22485, 22497)\t1\n",
      "  (22485, 22498)\t1\n",
      "  (22485, 22499)\t1\n",
      "  (22486, 22485)\t1\n",
      "  (22487, 22485)\t1\n",
      "  (22488, 22485)\t1\n",
      "  (22489, 22485)\t1\n",
      "  (22490, 22485)\t1\n",
      "  (22491, 22485)\t1\n",
      "  (22492, 22485)\t1\n",
      "  (22493, 22485)\t1\n",
      "  (22494, 22485)\t1\n",
      "  (22495, 22485)\t1\n",
      "  (22496, 22485)\t1\n",
      "  (22497, 22485)\t1\n",
      "  (22498, 22485)\t1\n",
      "  (22499, 22485)\t1\n",
      "tensor([[0.0940, 1.0000, 1.0000,  ..., 0.9589, 0.9587, 0.9566],\n",
      "        [0.0491, 0.9104, 0.8739,  ..., 0.5007, 0.4992, 0.4819],\n",
      "        [0.0515, 0.9167, 0.8826,  ..., 0.5252, 0.5237, 0.5069],\n",
      "        ...,\n",
      "        [0.0940, 1.0000, 1.0000,  ..., 0.9589, 0.9587, 0.9566],\n",
      "        [0.0943, 1.0005, 1.0007,  ..., 0.9621, 0.9620, 0.9601],\n",
      "        [0.0980, 1.0061, 1.0088,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "adjacency = nx.adjacency_matrix(extended_graph)\n",
    "# S = np.random.rand(target_number_point, target_number_point)\n",
    "print(adjacency)\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[137], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m A_s \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((target_number_point,target_number_point))   \u001b[38;5;66;03m# Init A_s to 0\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m A_s \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmatmul(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjacency\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, S\u001b[38;5;241m.\u001b[39mT)     \u001b[38;5;66;03m# A_s = S * A * S.T\u001b[39;00m\n\u001b[0;32m      3\u001b[0m A_s \u001b[38;5;241m=\u001b[39m A_s\u001b[38;5;241m/\u001b[39mA_s\u001b[38;5;241m.\u001b[39mmax()                                         \u001b[38;5;66;03m# Normalize\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Arthur\\miniconda3\\envs\\meshPFE\\lib\\site-packages\\torch\\_tensor.py:1030\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1028\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1030\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1032\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "A_s = np.zeros((target_number_point,target_number_point))   # Init A_s to 0\n",
    "A_s = np.matmul(np.matmul(S, adjacency.toarray()), S.T)     # A_s = S * A * S.T\n",
    "A_s = A_s/A_s.max()                                         # Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.21275686e-07 4.68134104e-07 4.21238709e-07 ... 1.15218045e-04\n",
      "  1.17097626e-04 1.19433965e-04]\n",
      " [4.68134104e-07 5.20338055e-07 4.69798077e-07 ... 1.31456383e-04\n",
      "  1.33615608e-04 1.36306884e-04]\n",
      " [4.21238709e-07 4.69798077e-07 4.24966061e-07 ... 1.11595096e-04\n",
      "  1.13405424e-04 1.15652511e-04]\n",
      " ...\n",
      " [1.15218045e-04 1.31456383e-04 1.11595096e-04 ... 1.05795152e-01\n",
      "  1.07810931e-01 1.10792495e-01]\n",
      " [1.17097626e-04 1.33615608e-04 1.13405424e-04 ... 1.07810931e-01\n",
      "  1.09865996e-01 1.12906390e-01]\n",
      " [1.19433965e-04 1.36306884e-04 1.15652511e-04 ... 1.10792495e-01\n",
      "  1.12906390e-01 1.16071338e-01]]\n",
      "(1500, 1500)\n"
     ]
    }
   ],
   "source": [
    "print(A_s)  # symmétrique\n",
    "print(A_s.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TriConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH UN-- 1500 11567 -- \n",
      "+ attr: name (v)\n"
     ]
    }
   ],
   "source": [
    "nodes = list(extended_graph.nodes())\n",
    "edges = list(extended_graph.edges())\n",
    "\n",
    "igraph_g = igraphGraph(directed=extended_graph.is_directed())\n",
    "\n",
    "igraph_g.add_vertices(nodes)\n",
    "igraph_g.add_edges([(nodes.index(u), nodes.index(v)) for u, v in edges])\n",
    "print(igraph_g.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 798  845 1006]\n",
      " [ 567  573  845]\n",
      " [1469 1471 1472]]\n",
      "31039\n"
     ]
    }
   ],
   "source": [
    "triangles_ids_igraph = np.array(igraph_g.cliques(min=3, max=3))\n",
    "print(triangles_ids_igraph[:3])\n",
    "print(len(triangles_ids_igraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 75.          -6.5098743    0.92127824]\n",
      "  [ 77.63298     -6.9390492    1.667854  ]\n",
      "  [ 75.          -5.0095077    2.234973  ]]\n",
      "\n",
      " [[ 81.81048     -8.760632    -3.010477  ]\n",
      "  [ 80.11056     -8.722893    -1.8758512 ]\n",
      "  [ 77.63298     -6.9390492    1.667854  ]]\n",
      "\n",
      " [[ 39.          -1.1623888  -13.722893  ]\n",
      "  [ 39.           0.16653232 -13.798424  ]\n",
      "  [ 39.           0.8314692  -13.760632  ]]]\n",
      "31039\n"
     ]
    }
   ],
   "source": [
    "triangles = np.array(igraph_g.vs['name'])[triangles_ids_igraph]\n",
    "# triangles = [list(map(tuple, row)) for row in triangles.tolist()]\n",
    "print(triangles[:3])\n",
    "print(len(triangles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract indices for each triangle\n",
    "i, j, k = triangles_ids_igraph.T\n",
    "\n",
    "# Extract probabilities using advanced indexing\n",
    "A_s_ij = A_s[i, j]\n",
    "A_s_ik = A_s[i, k]\n",
    "A_s_jk = A_s[j, k]\n",
    "\n",
    "# Calculate the barycenter probabilities\n",
    "p_init = np.zeros(len(igraph_g.vs))\n",
    "p_init[i] = (A_s_ij + A_s_ik + A_s_jk) / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate barycenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31039, 3)\n",
      "[[ 7.5877663e+01 -6.1528106e+00  1.6080351e+00]\n",
      " [ 7.9851341e+01 -8.1408577e+00 -1.0728248e+00]\n",
      " [ 3.9000000e+01 -5.4795761e-02 -1.3760650e+01]]\n"
     ]
    }
   ],
   "source": [
    "barycenters = np.mean(triangles, axis=1)\n",
    "print(barycenters.shape)\n",
    "print(barycenters[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Tri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, indices_neigh_tri = NearestNeighbors(n_neighbors=number_neigh_tri).fit(barycenters).kneighbors(barycenters)          # Find k='number_neigh_tri' neighbors of each triangles based on theirs barycenters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diff Barycenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31039, 19, 3)\n"
     ]
    }
   ],
   "source": [
    "# Calculates the difference between each barycenters and their n='number_neigh_tri'-1 neighbors\n",
    "barycenters_diff = np.subtract(barycenters[indices_neigh_tri[:, 0]][:, np.newaxis], barycenters[indices_neigh_tri[:, 1:]])   #Inverser la différence des barycentres si nécéssaire\n",
    "\n",
    "print(barycenters_diff.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate e norm matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31039, 3)\n",
      "[[2.770226  1.9942151 3.313207 ]\n",
      " [2.0441453 6.531189  4.677428 ]]\n"
     ]
    }
   ],
   "source": [
    "diff_vectors = list()\n",
    "\n",
    "for triangle in triangles:\n",
    "    e_ij = np.linalg.norm(np.array(triangle[0]) - np.array(triangle[1]))    #Calculate the vectors for each edge of each triangles\n",
    "    e_ik = np.linalg.norm(np.array(triangle[0]) - np.array(triangle[2]))\n",
    "    e_jk = np.linalg.norm(np.array(triangle[1]) - np.array(triangle[2]))\n",
    "    diff_vectors.append([e_ij, e_ik, e_jk])\n",
    "\n",
    "diff_vectors = np.array(diff_vectors)\n",
    "print(diff_vectors.shape)\n",
    "print(diff_vectors[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31039,)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_diff_vectors = diff_vectors.max(axis=1)       # calculate t_n_max\n",
    "min_diff_vectors = diff_vectors.min(axis=1)       # calculate t_n_min\n",
    "max_diff_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31039, 19)\n",
      "(31039, 19)\n"
     ]
    }
   ],
   "source": [
    "max_diff_vectors_diff = np.subtract(max_diff_vectors[indices_neigh_tri[:, 0]][:, np.newaxis], max_diff_vectors[indices_neigh_tri[:, 1:]])   #Inverser la différence des barycentres si nécéssaire   # calculate t_n_max - t_m_max\n",
    "print(max_diff_vectors_diff.shape)\n",
    "min_diff_vectors_diff = np.subtract(min_diff_vectors[indices_neigh_tri[:, 0]][:, np.newaxis], min_diff_vectors[indices_neigh_tri[:, 1:]])   #Inverser la différence des barycentres si nécéssaire   # calculate t_n_min - t_m_min\n",
    "print(min_diff_vectors_diff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31039, 19, 5)\n"
     ]
    }
   ],
   "source": [
    "r_matrix = np.zeros((len(triangles), number_neigh_tri-1, 5))\n",
    "\n",
    "r_matrix[:, :, 0]   = min_diff_vectors_diff\n",
    "r_matrix[:, :, 1]   = max_diff_vectors_diff\n",
    "r_matrix[:, :, 2:5] = barycenters_diff\n",
    "\n",
    "print(r_matrix.shape)  # nb_triangles, len(indices_neigh_tri), 5dim/triangles\n",
    "\n",
    "# Here r_matrix[i,j] represent the relation between the triangles (n = i) and (m = indices_neigh_tri_array[i,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999998\n",
      "(1500,)\n",
      "[0.00065867 0.00065867 0.00065867 ... 0.00073563 0.00065867 0.00065867]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basti\\AppData\\Local\\Temp\\ipykernel_17160\\1047055924.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  final_scores = torch.nn.functional.softmax(torch.tensor(f_final))\n"
     ]
    }
   ],
   "source": [
    "# Multi Layer Perceptron (MLP) * 3 \n",
    "f_final = p_init    # TODO\n",
    "\n",
    "\n",
    "final_scores = torch.nn.functional.softmax(torch.tensor(f_final))\n",
    "final_scores = final_scores.numpy()\n",
    "print(final_scores.sum())\n",
    "print(final_scores.shape)\n",
    "print(final_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 3, 3)\n",
      "[[[80.28243   -2.9401166 97.457664 ]\n",
      "  [80.20638   -3.5589852 97.223595 ]\n",
      "  [79.285     -4.1574683 97.191864 ]]]\n"
     ]
    }
   ],
   "source": [
    "selected_triangles_indexes = np.argpartition(final_scores, -int(target_number_point/3))[-int(target_number_point/3):] \n",
    "selected_triangles = np.array(triangles)[selected_triangles_indexes]\n",
    "print(selected_triangles.shape) # number triangles, number points, number dimensions(x,y,z)\n",
    "print(selected_triangles[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 440\n",
      "Number of edges: 907\n"
     ]
    }
   ],
   "source": [
    "simplified_final_graph = nx.Graph()\n",
    "for index_poly, poly in enumerate(selected_triangles):\n",
    "    for index_current_node in range(len(poly)):\n",
    "        current_node = tuple(poly[index_current_node])\n",
    "        for index_other_node in range(index_current_node+1, len(poly)):\n",
    "            edge = current_node, tuple(poly[index_other_node])\n",
    "            simplified_final_graph.add_edge(*edge)\n",
    "            # if attribute do not exists\n",
    "            if len(simplified_final_graph.nodes[current_node])==0:\n",
    "                simplified_final_graph.nodes[current_node]['index_triangle'] = set()\n",
    "            simplified_final_graph.nodes[current_node]['index_triangle'].add(index_poly)\n",
    "            if len(simplified_final_graph.nodes[tuple(poly[index_other_node])])==0:\n",
    "                simplified_final_graph.nodes[tuple(poly[index_other_node])]['index_triangle'] = set()\n",
    "            simplified_final_graph.nodes[tuple(poly[index_other_node])]['index_triangle'].add(index_poly)\n",
    "            \n",
    "transformation.print_graph_properties(graph=simplified_final_graph, display_graph=False, display_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_final_mesh = transformation.graph_to_mesh(simplified_final_graph)\n",
    "\n",
    "transformation.mesh_to_display_vtk(mesh_data)\n",
    "transformation.mesh_to_display_vtk(simplified_final_mesh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meshPFE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
