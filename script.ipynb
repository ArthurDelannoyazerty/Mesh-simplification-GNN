{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Transformation import Transformation\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import networkx as nx\n",
    "import torch\n",
    "from numpy import mean\n",
    "from igraph import Graph as igraphGraph\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import scipy.spatial.distance\n",
    "from scipy.spatial.distance import cdist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 5999\n",
      "Number of edges: 17991\n"
     ]
    }
   ],
   "source": [
    "transformation = Transformation()\n",
    "\n",
    "user_number_triangles = 500   #à diminuer si le process est trop long\n",
    "number_neigh_tri = 20\n",
    "\n",
    "# Create objects\n",
    "stl_file_path = \"3d_models/stl/Handle.stl\"\n",
    "mesh_data = transformation.stl_to_mesh(stl_file_path)\n",
    "graph = transformation.mesh_to_graph(mesh_data)\n",
    "\n",
    "transformation.print_graph_properties(graph, display_graph=False, display_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(graph._node)<20:\n",
    "    raise Exception(\"Input mesh does not have enough vertices. (More than 20 is needed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DevConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(array):\n",
    "    return np.maximum(array, 0)\n",
    "\n",
    "def sigmoid(array):\n",
    "    return 1 / (1 + np.exp(-array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DevConv():\n",
    "    def __init__(self, graph, output_dimension):\n",
    "        self.graph = graph\n",
    "        self.list_node = list(graph._node)\n",
    "\n",
    "        self.W_phi = np.random.random((output_dimension))      #change\n",
    "        self.W_theta = np.array([0.1, 0.1, 0.1]).reshape(1, -1)  # change\n",
    "    \n",
    "    def forward(self, previous_inclusion_score, return_flatten=True):\n",
    "        list_inc_score = np.zeros((len(self.list_node), len(self.W_phi)))                               #list of \"output_dimension\" for each \"list_node\" element\n",
    "        for index_current_node, (current_node, dict_neigh) in enumerate(self.graph._adj.items()):       # for each node and its adjacency nodes\n",
    "            neigh_nodes = np.array(list(dict_neigh.keys()))                                             # array of adjacency nodes\n",
    "            diff = current_node - neigh_nodes                                                           # Compute the differences between current_node and all neighbor nodes   (x_i - x_j)\n",
    "            neigh_distances = np.linalg.norm(self.W_theta * diff, axis=1)                               # Compute the norm for each vector difference  ||W_theta * (x_i - x_j)||\n",
    "            list_inc_score[index_current_node] = self.W_phi * np.max(neigh_distances)                   # Add (W_phi * ||W_theta * (x_i - x_j)||) to the inclusion score list\n",
    "\n",
    "        if len(previous_inclusion_score)==0:                            # return if no previous inclusion score\n",
    "            if return_flatten:\n",
    "                list_inc_score = list_inc_score.flatten()\n",
    "            return list_inc_score\n",
    "        \n",
    "        if list_inc_score.shape[1]!=1:                                  # If inclusion score is not vector\n",
    "            list_inc_score = np.mean(list_inc_score, axis=1)            # Mean the matrix for each node\n",
    "\n",
    "        # array of array to array\n",
    "        if len(list_inc_score.shape)==2:                 \n",
    "            if list_inc_score.shape[1]==1:\n",
    "                list_inc_score = list_inc_score.flatten()\n",
    "\n",
    "        # Return the mean of previous and current inclusion score\n",
    "        return np.mean(np.array([previous_inclusion_score, list_inc_score], dtype=np.float64), axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.04127364 1.04187946 1.04127364 ... 0.96939069 1.40714958 0.96939069]\n",
      "[0.8303662  0.83084931 0.8303662  ... 0.77304297 1.12213486 0.77304296]\n",
      "[0.66966854 0.66975949 0.66966854 ... 0.65878875 0.72211903 0.65878875]\n",
      "(5999,)\n"
     ]
    }
   ],
   "source": [
    "devconv = DevConv(graph, 1)\n",
    "inclusion_score = devconv.forward(previous_inclusion_score=np.array([]))\n",
    "inclusion_score = relu(inclusion_score)\n",
    "print(inclusion_score)\n",
    "\n",
    "devconv = DevConv(graph, 64)\n",
    "inclusion_score = devconv.forward(previous_inclusion_score=inclusion_score)\n",
    "inclusion_score = relu(inclusion_score)\n",
    "print(inclusion_score)\n",
    "\n",
    "devconv = DevConv(graph, 1)\n",
    "inclusion_score = devconv.forward(previous_inclusion_score=inclusion_score)\n",
    "inclusion_score = sigmoid(inclusion_score)\n",
    "print(inclusion_score)\n",
    "print(inclusion_score.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "normalized_inclusion_score = inclusion_score / np.sum(inclusion_score)  # normalize for multinomial sampling\n",
    "normalized_inclusion_score = np.round(normalized_inclusion_score, 8)    # round to remove float imprecision\n",
    "\n",
    "number_throws = 500     # small:more randomness    |   big:less randomness\n",
    "mult_sampling = np.random.multinomial(number_throws, normalized_inclusion_score)\n",
    "print(mult_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[81.27219  ,  5.7970243, 95.28757  ],\n",
       "       [76.61191  ,  5.7970243, 96.536285 ],\n",
       "       [85.85287  ,  4.7321377, 93.253334 ],\n",
       "       [89.788124 ,  5.2797017, 86.876625 ],\n",
       "       [84.968575 ,  5.2797017, 93.51016  ]], dtype=float32)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_number_point = min(len(graph._node), user_number_triangles*3)   # number of points for the simplification\n",
    "\n",
    "index_k_nodes = np.argpartition(mult_sampling, -target_number_point)[-target_number_point:]     # Take the k (\"target_number_points\") largest values given by the multinomial sampling \n",
    "list_k_nodes = np.array(graph)[index_k_nodes]                                # Take the selected nodes (list of list of 3)\n",
    "list_k_nodes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN extended graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n_, indices = NearestNeighbors(n_neighbors=15).fit(list_k_nodes).kneighbors(list_k_nodes)        # KNN of the selected points\\n\\nextended_graph = nx.Graph()\\nfor index_poly, poly in enumerate(indices):                                 # For the neighbors of the 'index_poly' node\\n    current_node = tuple(list_k_nodes[poly[0]])                             # Tuple of the main node coordinates\\n    for index_other_node in poly[1:]:                                       # For every neighbors of the main node (main node is the first index)\\n        edge = current_node, tuple(list_k_nodes[index_other_node])          # Create an edge of two tuples\\n        extended_graph.add_edge(*edge)                                      # Add the edge to the graph\\n\\ntransformation.print_graph_properties(graph=extended_graph, display_graph=False, display_labels=False)\\n\""
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "_, indices = NearestNeighbors(n_neighbors=15).fit(list_k_nodes).kneighbors(list_k_nodes)        # KNN of the selected points\n",
    "\n",
    "extended_graph = nx.Graph()\n",
    "for index_poly, poly in enumerate(indices):                                 # For the neighbors of the 'index_poly' node\n",
    "    current_node = tuple(list_k_nodes[poly[0]])                             # Tuple of the main node coordinates\n",
    "    for index_other_node in poly[1:]:                                       # For every neighbors of the main node (main node is the first index)\n",
    "        edge = current_node, tuple(list_k_nodes[index_other_node])          # Create an edge of two tuples\n",
    "        extended_graph.add_edge(*edge)                                      # Add the edge to the graph\n",
    "\n",
    "transformation.print_graph_properties(graph=extended_graph, display_graph=False, display_labels=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 1500\n",
      "Number of edges: 11735\n"
     ]
    }
   ],
   "source": [
    "def knn_and_extended_graph(list_k_nodes_i, k_neighbors=15):\n",
    "    \"\"\"\n",
    "    Perform k-NN on the given points and construct an extended graph.\n",
    "\n",
    "    Parameters:\n",
    "    - list_k_nodes_i: array-like\n",
    "        List of coordinates of the selected points.\n",
    "    - k_neighbors: int, optional (default=15)\n",
    "        Number of neighbors for k-NN.\n",
    "\n",
    "    Returns:\n",
    "    - extended_graph_i: networkx.Graph\n",
    "        Extended graph.\n",
    "    \"\"\"\n",
    "\n",
    "    # Perform k-NN on the selected points\n",
    "    _, indices = NearestNeighbors(n_neighbors=k_neighbors).fit(list_k_nodes_i).kneighbors(list_k_nodes_i)\n",
    "\n",
    "    # Construct the extended graph\n",
    "    extended_graph_i = nx.Graph()\n",
    "    for poly in indices:\n",
    "        current_node = tuple(list_k_nodes_i[poly[0]])\n",
    "        for index_other_node in poly[1:]:\n",
    "            edge = current_node, tuple(list_k_nodes_i[index_other_node])\n",
    "            extended_graph_i.add_edge(*edge)\n",
    "\n",
    "    return extended_graph_i\n",
    "\n",
    "extended_graph = knn_and_extended_graph(list_k_nodes)\n",
    "transformation.print_graph_properties(graph=extended_graph, display_graph=False, display_labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 64)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devconv = DevConv(extended_graph, 64)\n",
    "inclusion_score = devconv.forward(previous_inclusion_score=np.array([]), return_flatten=False)\n",
    "inclusion_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "inclusion_score = [[f_1_1  , f_1_2  , ..., f_63_1  ],\n",
    "                    ...,\n",
    "                   [f_1_M-1, f_1_M-1, ..., f_63_M-1]]\n",
    "M = number of points\n",
    "64 = hidden dimensions\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "f = np.mean(inclusion_score, axis=1)                            # Flatten the matrix of inclusion score \n",
    "wq = np.random.rand(64)\n",
    "wk = np.random.rand(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "wq_f = wq.reshape(-1, 1) * f            # Wq*f\n",
    "wk_f = wk.reshape(-1, 1) * f            # Wq*f\n",
    "S = np.exp(np.dot(wq_f.T, wk_f))        # e^((wq_f.T)*(wk_f))\n",
    "\n",
    "nodes = list(extended_graph.nodes())                                                                                # list of nodes\n",
    "node_indices = {node: index for index, node in enumerate(nodes)}                                                    # dict{node: index}\n",
    "neighbors_indices = [[node_indices[neighbor] for neighbor in extended_graph.neighbors(node)] for node in nodes]     # List of list : [[neigh1 of node1, neigh2 of node1...], [neigh1 of node2, neigh2 of node2...]...]\n",
    "\n",
    "\n",
    "for index_current_node, neighbors_index in enumerate(neighbors_indices):        # For each neighbors of the 'index_current_node' node\n",
    "    sum_columns = np.sum(S[:, neighbors_index], axis=1)                         # Sum along the rows the values of the neighbors\n",
    "    S[index_current_node] = S[index_current_node] / sum_columns                 # And divide the current node columns by the sume of the neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S = S*np.random.choice([0, 1], size=S.shape)      # Add a random mask to emulate the 'sparse'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 14)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 11)\t1\n",
      "  (1, 12)\t1\n",
      "  (1, 13)\t1\n",
      "  (1, 14)\t1\n",
      "  :\t:\n",
      "  (1498, 1382)\t1\n",
      "  (1498, 1444)\t1\n",
      "  (1498, 1445)\t1\n",
      "  (1498, 1446)\t1\n",
      "  (1498, 1477)\t1\n",
      "  (1498, 1478)\t1\n",
      "  (1498, 1479)\t1\n",
      "  (1498, 1481)\t1\n",
      "  (1498, 1490)\t1\n",
      "  (1498, 1495)\t1\n",
      "  (1498, 1496)\t1\n",
      "  (1499, 1432)\t1\n",
      "  (1499, 1437)\t1\n",
      "  (1499, 1438)\t1\n",
      "  (1499, 1439)\t1\n",
      "  (1499, 1451)\t1\n",
      "  (1499, 1466)\t1\n",
      "  (1499, 1467)\t1\n",
      "  (1499, 1468)\t1\n",
      "  (1499, 1469)\t1\n",
      "  (1499, 1474)\t1\n",
      "  (1499, 1475)\t1\n",
      "  (1499, 1476)\t1\n",
      "  (1499, 1483)\t1\n",
      "  (1499, 1484)\t1\n",
      "[[7.17492767e-02 7.17703184e-02 7.17492768e-02 ... 7.18050255e-02\n",
      "  7.18050254e-02 7.38170614e-02]\n",
      " [1.00929269e+00 5.98517303e-02 5.97873916e-02 ... 5.99581600e-02\n",
      "  5.99581598e-02 6.69591673e-02]\n",
      " [1.12913959e+00 6.66881732e-01 6.70630129e-02 ... 6.71325237e-02\n",
      "  6.71325236e-02 6.98045070e-02]\n",
      " ...\n",
      " [1.02968898e+00 1.24988154e+00 1.10110086e+00 ... 5.65720195e-02\n",
      "  5.65720199e-02 3.81224268e-02]\n",
      " [1.02953851e+00 1.24919091e+00 1.10088299e+00 ... 9.17393669e-02\n",
      "  5.60503482e-02 3.37499651e-02]\n",
      " [5.11358325e+00 6.32377803e+00 5.41055731e+00 ... 1.31340724e+02\n",
      "  5.21389970e+02 1.03190679e-01]]\n"
     ]
    }
   ],
   "source": [
    "adjacency = nx.adjacency_matrix(extended_graph)\n",
    "# S = np.random.rand(target_number_point, target_number_point)\n",
    "print(adjacency)\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_s = np.zeros((target_number_point,target_number_point))   # Init A_s to 0\n",
    "A_s = np.matmul(np.matmul(S, adjacency.toarray()), S.T)     # A_s = S * A * S.T\n",
    "A_s = A_s/A_s.max()                                         # Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.53206797e-16 3.01755575e-16 3.36028533e-16 ... 9.13188228e-15\n",
      "  3.44038604e-15 7.01188158e-10]\n",
      " [3.01755575e-16 2.57874894e-16 2.88636684e-16 ... 7.89200287e-15\n",
      "  2.93084472e-15 6.32555179e-10]\n",
      " [3.36028533e-16 2.88636684e-16 3.23278711e-16 ... 8.65271459e-15\n",
      "  3.30086325e-15 6.62552119e-10]\n",
      " ...\n",
      " [9.13188228e-15 7.89200287e-15 8.65271459e-15 ... 3.57969080e-13\n",
      "  7.71007863e-14 5.45711300e-08]\n",
      " [3.44038604e-15 2.93084472e-15 3.30086325e-15 ... 7.71007863e-14\n",
      "  6.51088542e-14 2.27960547e-09]\n",
      " [7.01188158e-10 6.32555179e-10 6.62552119e-10 ... 5.45711300e-08\n",
      "  2.27960547e-09 2.56155600e-02]]\n",
      "(1500, 1500)\n"
     ]
    }
   ],
   "source": [
    "print(A_s)  # symmétrique\n",
    "print(A_s.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TriConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH UN-- 1500 11735 -- \n",
      "+ attr: name (v)\n"
     ]
    }
   ],
   "source": [
    "nodes = list(extended_graph.nodes())\n",
    "edges = list(extended_graph.edges())\n",
    "\n",
    "igraph_g = igraphGraph(directed=extended_graph.is_directed())\n",
    "\n",
    "igraph_g.add_vertices(nodes)\n",
    "igraph_g.add_edges([(nodes.index(u), nodes.index(v)) for u, v in edges])\n",
    "print(igraph_g.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[709 779 780]\n",
      " [779 780 951]\n",
      " [896 929 930]]\n",
      "32095\n"
     ]
    }
   ],
   "source": [
    "triangles_ids_igraph = np.array(igraph_g.cliques(min=3, max=3))\n",
    "print(triangles_ids_igraph[:3])\n",
    "print(len(triangles_ids_igraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[75.         6.0434117  1.3966535]\n",
      "  [77.26702    6.9390492  1.2822151]\n",
      "  [77.517784   6.9390492  1.5329764]]\n",
      "\n",
      " [[77.26702    6.9390492  1.2822151]\n",
      "  [77.517784   6.9390492  1.5329764]\n",
      "  [78.63775    7.6759295  1.1570231]]\n",
      "\n",
      " [[77.49305   -6.5098743 82.63936  ]\n",
      "  [77.13951   -7.328478  84.49455  ]\n",
      "  [77.44897   -7.6759295 84.971085 ]]]\n",
      "32095\n"
     ]
    }
   ],
   "source": [
    "triangles = np.array(igraph_g.vs['name'])[triangles_ids_igraph]   #les triangles\n",
    "# triangles = [list(map(tuple, row)) for row in triangles.tolist()]\n",
    "print(triangles[:3])\n",
    "print(len(triangles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32095,)\n",
      "[5.20771767e-11 5.54085308e-13 9.13701344e-13 ... 2.79686702e-09\n",
      " 5.62950509e-10 1.35932848e-09]\n"
     ]
    }
   ],
   "source": [
    "# Extract indices for each triangle\n",
    "i, j, k = triangles_ids_igraph.T\n",
    "\n",
    "# Extract probabilities using advanced indexing\n",
    "A_s_ij = A_s[i, j]\n",
    "A_s_ik = A_s[i, k]\n",
    "A_s_jk = A_s[j, k]\n",
    "\n",
    "# Calculate the barycenter probabilities\n",
    "p_init = np.zeros(len(triangles))\n",
    "p_init = (A_s_ij + A_s_ik + A_s_jk) / 3\n",
    "\n",
    "print(p_init.shape)\n",
    "print(p_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate barycenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32095, 3)\n",
      "[[76.59494    6.6405034  1.4039484]\n",
      " [77.80752    7.1846757  1.3240715]\n",
      " [77.36051   -7.1714272 84.034996 ]]\n"
     ]
    }
   ],
   "source": [
    "barycenters = np.mean(triangles, axis=1)\n",
    "print(barycenters.shape)\n",
    "print(barycenters[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Tri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, indices_neigh_tri = NearestNeighbors(n_neighbors=number_neigh_tri).fit(barycenters).kneighbors(barycenters)          # Find k='number_neigh_tri' neighbors of each triangles based on theirs barycenters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diff Barycenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32095, 19, 3)\n"
     ]
    }
   ],
   "source": [
    "# Calculates the difference between each barycenters and their n='number_neigh_tri'-1 neighbors\n",
    "barycenters_diff = np.subtract(barycenters[indices_neigh_tri[:, 0]][:, np.newaxis], barycenters[indices_neigh_tri[:, 1:]])   #Inverser la différence des barycentres si nécéssaire\n",
    "\n",
    "print(barycenters_diff.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate e norm matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32095, 3)\n",
      "[[2.4402146 2.675815  0.3546312]\n",
      " [0.3546312 1.5612686 1.3923557]]\n"
     ]
    }
   ],
   "source": [
    "diff_vectors = list()\n",
    "\n",
    "for triangle in triangles:\n",
    "    e_ij = np.linalg.norm(np.array(triangle[0]) - np.array(triangle[1]))    #Calculate the vectors for each edge of each triangles\n",
    "    e_ik = np.linalg.norm(np.array(triangle[0]) - np.array(triangle[2]))\n",
    "    e_jk = np.linalg.norm(np.array(triangle[1]) - np.array(triangle[2]))\n",
    "    diff_vectors.append([e_ij, e_ik, e_jk])\n",
    "\n",
    "diff_vectors = np.array(diff_vectors)\n",
    "print(diff_vectors.shape)\n",
    "print(diff_vectors[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32095,)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_diff_vectors = diff_vectors.max(axis=1)       # calculate t_n_max\n",
    "min_diff_vectors = diff_vectors.min(axis=1)       # calculate t_n_min\n",
    "max_diff_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32095, 19)\n",
      "(32095, 19)\n"
     ]
    }
   ],
   "source": [
    "max_diff_vectors_diff = np.subtract(max_diff_vectors[indices_neigh_tri[:, 0]][:, np.newaxis], max_diff_vectors[indices_neigh_tri[:, 1:]])   #Inverser la différence des barycentres si nécéssaire   # calculate t_n_max - t_m_max\n",
    "print(max_diff_vectors_diff.shape)\n",
    "min_diff_vectors_diff = np.subtract(min_diff_vectors[indices_neigh_tri[:, 0]][:, np.newaxis], min_diff_vectors[indices_neigh_tri[:, 1:]])   #Inverser la différence des barycentres si nécéssaire   # calculate t_n_min - t_m_min\n",
    "print(min_diff_vectors_diff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32095, 19, 5)\n"
     ]
    }
   ],
   "source": [
    "r_matrix = np.zeros((len(triangles), number_neigh_tri-1, 5))\n",
    "\n",
    "r_matrix[:, :, 0]   = min_diff_vectors_diff\n",
    "r_matrix[:, :, 1]   = max_diff_vectors_diff\n",
    "r_matrix[:, :, 2:5] = barycenters_diff\n",
    "\n",
    "print(r_matrix.shape)  # nb_triangles, len(indices_neigh_tri), 5dim/triangles\n",
    "\n",
    "# Here r_matrix[i,j] represent the relation between the triangles (n = i) and (m = indices_neigh_tri_array[i,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000269\n",
      "(32095,)\n",
      "[3.11240170e-05 3.11240170e-05 3.11240170e-05 ... 3.11240171e-05\n",
      " 3.11240170e-05 3.11240170e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arthur\\AppData\\Local\\Temp\\ipykernel_5324\\474768578.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  final_scores = torch.nn.functional.softmax(torch.tensor(f_final))    #proba des triangles\n"
     ]
    }
   ],
   "source": [
    "# Multi Layer Perceptron (MLP) * 3 \n",
    "f_final = p_init    # TODO\n",
    "\n",
    "\n",
    "final_scores = torch.nn.functional.softmax(torch.tensor(f_final))    #proba des triangles\n",
    "final_scores = final_scores.numpy()\n",
    "print(final_scores.sum())\n",
    "print(final_scores.shape)\n",
    "print(final_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 3, 3)\n",
      "[[51.         6.1633806 83.71886  ]\n",
      " [39.         7.0402236 84.7203   ]\n",
      " [39.         8.642877  88.3445   ]]\n"
     ]
    }
   ],
   "source": [
    "selected_triangles_indexes = np.argpartition(final_scores, -int(target_number_point/3))[-int(target_number_point/3):] \n",
    "selected_triangles = np.array(triangles)[selected_triangles_indexes]\n",
    "print(selected_triangles.shape) # number triangles, number points, number dimensions(x,y,z)\n",
    "print(selected_triangles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 53\n",
      "Number of edges: 243\n"
     ]
    }
   ],
   "source": [
    "simplified_final_graph = nx.Graph()\n",
    "for index_poly, poly in enumerate(selected_triangles):\n",
    "    for index_current_node in range(len(poly)):\n",
    "        current_node = tuple(poly[index_current_node])\n",
    "        for index_other_node in range(index_current_node+1, len(poly)):\n",
    "            edge = current_node, tuple(poly[index_other_node])\n",
    "            simplified_final_graph.add_edge(*edge)\n",
    "            # if attribute do not exists\n",
    "            if len(simplified_final_graph.nodes[current_node])==0:\n",
    "                simplified_final_graph.nodes[current_node]['index_triangle'] = set()\n",
    "            simplified_final_graph.nodes[current_node]['index_triangle'].add(index_poly)\n",
    "            if len(simplified_final_graph.nodes[tuple(poly[index_other_node])])==0:\n",
    "                simplified_final_graph.nodes[tuple(poly[index_other_node])]['index_triangle'] = set()\n",
    "            simplified_final_graph.nodes[tuple(poly[index_other_node])]['index_triangle'].add(index_poly)\n",
    "            \n",
    "transformation.print_graph_properties(graph=simplified_final_graph, display_graph=False, display_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_final_mesh = transformation.graph_to_mesh(simplified_final_graph)\n",
    "\n",
    "#Affichage\n",
    "transformation.mesh_to_display_vtk(mesh_data)\n",
    "transformation.mesh_to_display_vtk(simplified_final_mesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Chamfer distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des points de l'espace de départ P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les points avant K-NN :  [[75.0252     -0.66553295  3.8       ]\n",
      " [75.01418    -0.49935842 16.7       ]\n",
      " [75.          0.          3.8       ]\n",
      " ...\n",
      " [51.         -8.57404    -6.9813724 ]\n",
      " [39.         -8.699333   -6.327254  ]\n",
      " [51.         -8.699333   -6.327254  ]]\n",
      "dim points avant K-NN :  5999\n"
     ]
    }
   ],
   "source": [
    "keys_input = np.array(graph)\n",
    "print(\"Les points avant K-NN : \", keys_input)\n",
    "print(\"dim points avant K-NN : \", len(keys_input))  #return 5999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des points de l'espace de départ Ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled points :  [[ 81.27219     5.7970243  95.28757  ]\n",
      " [ 81.08616     6.2811418  94.86973  ]\n",
      " [ 82.00088     5.7970243  94.94     ]\n",
      " ...\n",
      " [ 81.9768     -7.8332825  91.94333  ]\n",
      " [ 80.21027    -7.8332825  92.90247  ]\n",
      " [ 39.          6.620764  -10.797024 ]]\n",
      "dim sample points :  1500\n"
     ]
    }
   ],
   "source": [
    "keys_output = np.array(extended_graph)\n",
    "print(\"sampled points : \", keys_output)\n",
    "print(\"dim sample points : \", len(keys_output))  #return: 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squared Euclidean Distances Matrix Shape: (1500, 5999)\n",
      "Distances Matrix:\n",
      " [[ 8450.76443414  6254.81262802  8442.92076056 ... 11581.86874712\n",
      "  12322.65395005 11452.12147934]\n",
      " [ 8378.68689456  6193.35034174  8370.18945292 ... 11499.50004762\n",
      "  12236.48853529 11370.42072523]\n",
      " [ 8396.92477568  6209.95619506  8389.11782796 ... 11555.54853858\n",
      "  12314.27702495 11426.25596782]\n",
      " ...\n",
      " [ 7868.94779405  5763.82288588  7879.28246918 ... 10746.20730956\n",
      "  11504.86271657 10617.4195403 ]\n",
      " [ 8017.51240745  5887.60264417  8027.75805009 ... 10830.57146747\n",
      "  11545.57547952 10700.5289097 ]\n",
      " [ 1563.97824874  2103.80387876  1552.90761466 ...   389.44127016\n",
      "    254.68421461   398.68421461]]\n"
     ]
    }
   ],
   "source": [
    "def matrix_distance_euclidienne_barycentres(barycentre_b, barycentre_b_hat):\n",
    "    \"\"\"\n",
    "    Calculate distances between barycenters b et b_hat after the k-NN process.\n",
    "\n",
    "    Parameters:\n",
    "    - b_hat: array-like, shape (M, 3)\n",
    "        Barycenters after k-NN.\n",
    "    - number_neigh: int, optional (default=3)\n",
    "        Number of neighbors for k-NN.\n",
    "\n",
    "    Returns:\n",
    "    - distances_after: array-like, shape (M, M)\n",
    "        Matrix of distances between barycenters after the k-NN process.\n",
    "    \"\"\"\n",
    "    return cdist(barycentre_b, barycentre_b_hat, metric='sqeuclidean').T\n",
    "\n",
    "distances_matrix = matrix_distance_euclidienne_barycentres(keys_input, keys_output)\n",
    "print(\"Squared Euclidean Distances Matrix Shape:\", distances_matrix.shape)\n",
    "print(\"Distances Matrix:\\n\", distances_matrix)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le min des x de distances_matrix\n",
    "def min_pour_x_list(distances_matrix, x_in):\n",
    "    return np.min(distances_matrix[:, x_in])\n",
    "\n",
    "# Calculer le min des y de distances_matrix\n",
    "def min_pour_y_list(distances_matrix, y_out):\n",
    "    return np.min(distances_matrix[y_out, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_P_Ps(keys_x, keys_y, p_y):\n",
    "    \"\"\"\n",
    "    Calculate the Probabilistic Chamfer distance between two sets of points.\n",
    "\n",
    "    Parameters:\n",
    "    - keys_x (list): The input vertex set, a list of tuples.\n",
    "    - keys_y (list): The sampled points, a list of tuples.\n",
    "    - p_y (list): Their respective probabilities, a weight associated with each point in keys_y.\n",
    "\n",
    "    Returns:\n",
    "        chamfer_distance (float): The Probabilistic Chamfer distance between the two sets of points.\n",
    "    \"\"\"\n",
    "    min_for_x = [p_y[i] * min_pour_x_list(distances_matrix, i) for i in range(len(keys_x))]\n",
    "    min_for_y = [p_y[j] * min_pour_y_list(distances_matrix, j) for j in range(len(keys_y))]\n",
    "    \n",
    "    sum_for_y = np.sum(min_for_y)\n",
    "    sum_for_x = np.sum(min_for_x)\n",
    "\n",
    "    chamfer_distance = sum_for_y + sum_for_x\n",
    "    \n",
    "    return chamfer_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROBA :  [0.00020521 0.00020524 0.00020521 ... 0.00020188 0.00022129 0.00020188]\n"
     ]
    }
   ],
   "source": [
    "print(\"PROBA : \", normalized_inclusion_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chamfer Distance: 2.6621353009661055\n"
     ]
    }
   ],
   "source": [
    "prob_chamfer_dist = d_P_Ps(keys_input, keys_output, normalized_inclusion_score)\n",
    "print(\"Chamfer Distance:\", prob_chamfer_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Surfaces Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "barycentres b et b_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH UN-- 5999 17991 -- \n",
      "+ attr: name (v)\n",
      "triangles shape :  (11994, 3, 3)\n",
      "[[39.        8.793697 -4.666995]\n",
      " [51.        8.793697 -4.666995]\n",
      " [39.        8.793697 -5.333005]]\n",
      "shape b :  (11994, 3)\n",
      "Barycentre b:  [[43.          8.793697   -4.8889985 ]\n",
      " [55.          1.0515273   3.7313068 ]\n",
      " [55.         -8.515905   -2.804371  ]\n",
      " ...\n",
      " [75.05613    -0.94137865 21.        ]\n",
      " [75.01313    -0.3882971   8.099999  ]\n",
      " [75.03516    -0.72036856 25.300001  ]]\n"
     ]
    }
   ],
   "source": [
    "# Creation igraph\n",
    "nodes_original = list(graph.nodes())\n",
    "edges_original = list(graph.edges())\n",
    "igraph_g_original = igraphGraph(directed=extended_graph.is_directed())\n",
    "igraph_g_original.add_vertices(nodes_original)\n",
    "igraph_g_original.add_edges([(nodes_original.index(u), nodes_original.index(v)) for u, v in edges_original])\n",
    "print(igraph_g_original.summary())\n",
    "\n",
    "#Find triangles\n",
    "triangles_ids_igraph_original = np.array(igraph_g_original.cliques(min=3, max=3))\n",
    "triangles = np.array(igraph_g_original.vs['name'])[triangles_ids_igraph_original]\n",
    "print(\"triangles shape : \", triangles.shape)\n",
    "print(triangles[0])\n",
    "\n",
    "# Calculate barycenters\n",
    "b = np.mean(triangles, axis=1)\n",
    "print(\"shape b : \", b.shape)\n",
    "print(\"Barycentre b: \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 3)\n",
      "B_HAT :  [[ 4.3000000e+01  7.2821603e+00  8.5594543e+01]\n",
      " [ 5.1000000e+01  6.7756653e+00  8.4895058e+01]\n",
      " [ 3.9000000e+01  2.5407698e+00 -7.8802980e-02]\n",
      " ...\n",
      " [ 3.9000000e+01  5.4586381e-01 -1.1749581e+00]\n",
      " [ 3.9000000e+01  5.5426472e-01 -1.3968025e+00]\n",
      " [ 3.9000000e+01  2.8539190e+00  8.8019569e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Get finals selected triangles & calculate barycenters\n",
    "b_hat = np.mean(selected_triangles, axis=1)\n",
    "print(b_hat.shape)\n",
    "print(\"B_HAT : \", b_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test matrice des normes euclidiennes entre b et b_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 11994)\n",
      "Distances euclidiennes entre les barycentres b et b_hat :\n",
      " [[8189.55611095 6884.41030522 8207.94697681 ... 5267.67707271\n",
      "  7089.08077535 4725.72353659]\n",
      " [8129.24919878 6636.32021412 7941.02194463 ... 4720.8285272\n",
      "  6525.43375029 4185.45002267]\n",
      " [  78.23708386  272.73477986  385.67878806 ... 1756.48576436\n",
      "  1372.41778783 1953.2512083 ]\n",
      " ...\n",
      " [  97.82085435  280.32713081  340.77064756 ... 1793.98512863\n",
      "  1383.84303988 2001.0592979 ]\n",
      " [  96.08368276  282.54477539  340.24923502 ... 1803.89818465\n",
      "  1388.02321645 2012.87650319]\n",
      " [8683.28295682 7363.75982917 8634.26107787 ... 5806.07143797\n",
      "  7694.59517549 5245.05225955]]\n"
     ]
    }
   ],
   "source": [
    "distances = matrix_distance_euclidienne_barycentres(b, b_hat)\n",
    "print(distances.shape)\n",
    "print(\"Distances euclidiennes entre les barycentres b et b_hat :\\n\", distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "[ 0.13395437 16.13610641  1.40520565 24.98210947 16.52787497]\n"
     ]
    }
   ],
   "source": [
    "minimums_b = np.min(distances, axis=1)\n",
    "print(minimums_b.shape)\n",
    "print(minimums_b[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42164893.50211412\n"
     ]
    }
   ],
   "source": [
    "d_f_S_Ss = np.sum(selected_triangles_indexes * minimums_b)\n",
    "print(d_f_S_Ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matrice sqeuclidean b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11994,)\n",
      "[1950.2314 3040.0283 3105.3853 ... 6075.3086 5692.7305 6270.884 ]\n"
     ]
    }
   ],
   "source": [
    "def normes_euclidiennes_carrees_b(bar_b):\n",
    "    # Calculer la matrice des normes euclidiennes au carré\n",
    "    normes_carrees = np.sum(bar_b**2, axis=1)\n",
    "\n",
    "    return normes_carrees\n",
    "\n",
    "matrix_b = normes_euclidiennes_carrees_b(b)\n",
    "print(matrix_b.shape)\n",
    "print(matrix_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances After k-NN:\n",
      " [[ 0.          0.22200068  0.4237945  ... 14.54013091 14.90515569\n",
      "  14.57769275]\n",
      " [ 0.22200068  0.          0.22199403 ... 14.51659334 14.8849859\n",
      "  14.63643622]\n",
      " [ 0.4237945   0.22199403  0.         ... 14.6207881  14.9922894\n",
      "  14.80831344]\n",
      " ...\n",
      " [14.54013091 14.51659334 14.6207881  ...  0.          0.44368622\n",
      "   6.72768351]\n",
      " [14.90515569 14.8849859  14.9922894  ...  0.44368622  0.\n",
      "   6.57809029]\n",
      " [14.57769275 14.63643622 14.80831344 ...  6.72768351  6.57809029\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "def matrix_distances_after_knn(b_hat_n, number_neigh=3):\n",
    "    \"\"\"\n",
    "    Calculate distances between barycenters after the k-NN process.\n",
    "\n",
    "    Parameters:\n",
    "    - b_hat: array-like, shape (M, 3)\n",
    "        Barycenters after k-NN.\n",
    "    - number_neigh: int, optional (default=3)\n",
    "        Number of neighbors for k-NN.\n",
    "\n",
    "    Returns:\n",
    "    - distances_after: array-like, shape (M, M)\n",
    "        Matrix of distances between barycenters after the k-NN process.\n",
    "    \"\"\"\n",
    "\n",
    "    # Connect the extended graph using the k-NN process\n",
    "    extended_graph = knn_and_extended_graph(b_hat_n, number_neigh)\n",
    "\n",
    "    # Extract barycenters after the k-NN process\n",
    "    b_hat_extended = np.array(list(extended_graph._node.keys()))\n",
    "\n",
    "    # Calculate distances after k-NN\n",
    "    distances_after = cdist(b_hat_extended, b_hat_extended)\n",
    "\n",
    "    return distances_after\n",
    "\n",
    "# Example usage with b_hat\n",
    "distances_after = matrix_distances_after_knn(b_hat)\n",
    "\n",
    "# Print the results\n",
    "print(\"Distances After k-NN:\\n\", distances_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b shape: (11994, 3)\n",
      "b_hat shape: (500, 3)\n",
      "p_b_hat shape: (5999,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (497,497) (11994,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[398], line 32\u001b[0m\n\u001b[0;32m     26\u001b[0m     d_S_Ss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(p_b_hat_i \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(np\u001b[38;5;241m.\u001b[39msum(dist_matrixs_1)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m d_S_Ss\n\u001b[1;32m---> 32\u001b[0m result_distance \u001b[38;5;241m=\u001b[39m \u001b[43mprobabilistic_surface_distance_extended\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_inclusion_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProbabilistic Surfaces Distance:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result_distance)\n",
      "Cell \u001b[1;32mIn[398], line 23\u001b[0m, in \u001b[0;36mprobabilistic_surface_distance_extended\u001b[1;34m(b_i, b_hat_i, p_b_hat_i)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp_b_hat shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, p_b_hat_i\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     22\u001b[0m p_b_hat_i \u001b[38;5;241m=\u001b[39m normalized_inclusion_score\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m---> 23\u001b[0m dist_matrixs_1\u001b[38;5;241m=\u001b[39m \u001b[43mdistances_after\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmatrix_b\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#dist_matrixs_2= matrix_b - distances_after\u001b[39;00m\n\u001b[0;32m     26\u001b[0m d_S_Ss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(p_b_hat_i \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(np\u001b[38;5;241m.\u001b[39msum(dist_matrixs_1)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (497,497) (11994,) "
     ]
    }
   ],
   "source": [
    "def probabilistic_surface_distance_extended(b_i, b_hat_i, p_b_hat_i):\n",
    "    \"\"\"\n",
    "    Calculate Probabilistic Surfaces Distance \n",
    "\n",
    "    Parameters:\n",
    "    - b: array-like, shape (N, 3)\n",
    "        Barycenters of the ground truth surface.\n",
    "    - b_hat: array-like, shape (M, 3)\n",
    "        Barycenters of the generated triangles.\n",
    "    - p_b_hat: array-like, shape (M,)\n",
    "        Probabilities corresponding to the generated triangles.\n",
    "\n",
    "    Returns:\n",
    "    - d_S_Ss: float\n",
    "        Probabilistic Surfaces Distance.\n",
    "    \"\"\"\n",
    "    # Debugging print statements\n",
    "    print(\"b shape:\", b_i.shape)\n",
    "    print(\"b_hat shape:\", b_hat_i.shape)\n",
    "    print(\"p_b_hat shape:\", p_b_hat_i.shape)\n",
    "\n",
    "    p_b_hat_i = normalized_inclusion_score.reshape((-1, 1))\n",
    "    dist_matrixs_1= distances_after - matrix_b\n",
    "    #dist_matrixs_2= matrix_b - distances_after\n",
    "\n",
    "    d_S_Ss = np.sum(p_b_hat_i * np.min(np.sum(dist_matrixs_1)**2))\n",
    "\n",
    "    \n",
    "\n",
    "    return d_S_Ss\n",
    "\n",
    "result_distance = probabilistic_surface_distance_extended(b, b_hat, normalized_inclusion_score)\n",
    "print(\"Probabilistic Surfaces Distance:\", result_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triangle Collision Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangle_collision_loss(generated_triangles, probabilities):\n",
    "    \"\"\"\n",
    "    Calculate triangle collision loss to penalize triangles that penetrate each other.\n",
    "\n",
    "    Parameters:\n",
    "    - generated_triangles (numpy.ndarray): Array representing the generated triangles.\n",
    "    - probabilities (numpy.ndarray): Array of probabilities for each generated triangle.\n",
    "\n",
    "    Returns:\n",
    "    - float: Triangle collision loss.\n",
    "    \"\"\"\n",
    "    num_triangles = len(generated_triangles)\n",
    "\n",
    "    # Create a 3D array to represent all combinations of triangle pairs\n",
    "    triangle_pairs_i, triangle_pairs_j = np.meshgrid(range(num_triangles), range(num_triangles), indexing='ij')\n",
    "\n",
    "    # Filter out pairs where i is not equal to j\n",
    "    valid_pairs_mask = triangle_pairs_i != triangle_pairs_j\n",
    "\n",
    "    # Extract triangles and probabilities for each pair\n",
    "    triangles_i = generated_triangles[triangle_pairs_i[valid_pairs_mask]]\n",
    "    triangles_j = generated_triangles[triangle_pairs_j[valid_pairs_mask]]\n",
    "    probs_i = probabilities[triangle_pairs_i[valid_pairs_mask]]\n",
    "\n",
    "    # Calculate the plane normals and distances for all triangles\n",
    "    plane_normals = np.cross(triangles_i[:, 1] - triangles_i[:, 0], triangles_i[:, 2] - triangles_i[:, 0])\n",
    "\n",
    "    # Calculate the edge vectors for all edges of triangles_j\n",
    "    edge_vectors = triangles_j[:, [1, 2, 0], :] - triangles_j[:, [0, 1, 2], :]\n",
    "\n",
    "    # Calculate the dot product of edge vectors and plane normals\n",
    "    dot_products = np.sum(np.cross(edge_vectors, plane_normals[:, np.newaxis, :]) * triangles_i[:, 0], axis=2)\n",
    "\n",
    "    # Count the number of faces penetrated for each triangle\n",
    "    faces_penetrated = np.sum(dot_products < 0, axis=1)\n",
    "\n",
    "    # Calculate the loss for each triangle\n",
    "    loss_per_triangle = probs_i * faces_penetrated\n",
    "\n",
    "    # Sum up the losses and normalize by the number of triangles\n",
    "    triangle_losses = np.sum(loss_per_triangle) / num_triangles\n",
    "\n",
    "    return triangle_losses\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meshPFE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
